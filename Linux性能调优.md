[toc]



# Linux性能调优

## CPU性能篇

### 2 怎么理解“平均负载”



### 3 CPU上下文切换（上）

> CPU上下文：包括CPU寄存器和程序计数器
>
> CPU寄存器：是 CPU 内置的容量小、但速度极快的内存
>
> 程序计数器：是用来存储 CPU 正在执行的指令位置、或者即将执行的下一条指令位置

![img](https://static001.geekbang.org/resource/image/98/5f/98ac9df2593a193d6a7f1767cd68eb5f.png)

* CPU上下文切换：是先把前一个任务的 CPU 上下文（也就是**CPU 寄存器和程序计数器**）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务
* 这些这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来

根据任务的不同，CPU的上下文切换分为进程上下文切换、线程上下文切换和中断下文切换

#### 3.1 进程上下文切换

Linux 按照特权等级，把进程的运行空间分为内核空间和用户空间，分别对应着下图中， CPU 特权等级的 Ring 0 和 Ring 3。

* 内核空间（Ring 0）具有最高权限，可以直接访问所有资源；
* 用户空间（Ring 3）只能访问受限资源，不能直接访问内存等硬件设备，必须通过系统调用陷入到内核中，才能访问这些特权资源。

![img](https://static001.geekbang.org/resource/image/4d/a7/4d3f622f272c49132ecb9760310ce1a7.png)

从进程用户态到内核态的转变，需要通过**系统调用**来完成，系统调用的过程中会发生**两次CPU上下文切换**。CPU里原来用户态指令的执行位置需要先保存起来，然后更新为内核态执行的指令位置，最后跳转到内核态运行内核任务。在系统调用结束后，CPU 寄存器需要恢复原来保存的用户态，然后再切换到用户空间，继续运行进程。

**注意**：

1. 系统调用的过程中，不会涉及到虚拟内存等进程态的资源，不会切换进程，系统调用过程和进程上下文切换不一样，整个过程都是同一个进程

2. 系统调用称为特权模式切换，不是上下文切换

进程上下文切换和系统调用的区别：

进程的上下文切换就比系统调用时多了一步：在保存当前进程的内核状态和 CPU 寄存器之前，需要先把该进程的**虚拟内存、栈**等保存下来；而加载了下一进程的内核态后，还需要刷新进程的虚拟内存和用户栈

![img](https://static001.geekbang.org/resource/image/39/6b/395666667d77e718da63261be478a96b.png)

**保存上下文和恢复上下文的过程需要内核在CPU上运行才能完成**（上下文切换过程是CPU密集型），每次上下文切换都需要几十纳秒到数微秒的 CPU 时间。

在进程上下文切换次数较多的情况下，很容易导致 CPU 将大量时间耗费在**寄存器、内核栈以及虚拟内存**等资源的保存和恢复上，进而大大缩短了真正运行进程的时间，从而导致系统平均负载升高。

Linux 通过 TLB（Translation Lookaside Buffer）来管理虚拟内存到物理内存的映射关系。当虚拟内存更新后，TLB 也需要刷新，内存的访问也会随之变慢。特别是在**多处理器系统**上，缓存是被多个处理器**共享**的，刷新缓存不仅会影响当前处理器的进程，还会影响共享缓存的其他处理器的进程。

Linux 为每个 CPU 都维护了一个就绪队列，将活跃进程（即正在运行和正在等待 CPU 的进程）按照优先级和等待 CPU 的时间排序，然后选择最需要 CPU 的进程，也就是**优先级最高和等待 CPU 时间最长**的进程来运行。

进程被CPU重新调度的时机：

1. 进程执行完终止了，它之前使用的 CPU 会释放出来，这个时候再从就绪队列里，拿一个新的进程过来运行
2. 为了保证所有进程可以得到公平调度，CPU 时间被划分为一段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的时间片耗尽了，就会被系统挂起，切换到其它正在等待 CPU 的进程运行
3. 进程在系统**资源**不足（比如内存不足）时，要等到资源满足后才可以运行，这个时候进程也会被挂起，并由系统调度其他进程运行
4. 进程通过睡眠函数  sleep 这样的方法将自己主动挂起时，自然也会重新调度
5. 有优先级更高的进程运行时，为了保证高优先级进程的运行，当前进程会被挂起，由高优先级进程来运行
6. 发生硬件中断时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序

#### 3.2 线程上下文切换

线程和进程的区别：**线程是调度的基本单位，而进程则是资源拥有的基本单位**。

所谓内核中的任务调度，实际上的调度对象是**线程**；而进程只是给线程提供了虚拟内存、全局变量等资源。

* 当进程只有一个线程时，可以认为进程就等于线程
* 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源。这些资源在上下文切换时是不需要修改的
* 另外，线程也有自己的私有数据，比如栈和寄存器等，这些在上下文切换时也是需要保存的

因此，线程的上下文切换分为两种情况：

1. 前后两个线程属于不同进程。此时，因为资源不共享，所以切换过程就跟进程上下文切换是一样
2. 前后两个线程属于同一个进程。此时，因为虚拟内存是共享的，所以在切换时，虚拟内存这些资源就保持不动，只需要切换线程的**私有数据、寄存器**等不共享的数据

**注意**：同进程的线程切换要比进程间的切换消耗更少的资源，更加轻量级

#### 3.3 中断上下文切换

为了响应硬件事件，**中断处理会打断进程的正常调度和执行**，转而调用中断处理程序，响应设备事件。

中断上下文切换不会涉及到进程的用户态，它其实只包括内核态中断服务程序执行所必需的状态，包括**CPU 寄存器、内核堆栈、硬件中断参数**等

对同一个 CPU 来说，中断处理比进程拥有更高的优先级，所以**中断上下文切换并不会与进程上下文切换同时发生**

大部分中断处理程序都短小精悍，以便尽可能快的执行结束。

中断上下文切换也需要消耗 CPU，切换次数过多也会耗费大量的 CPU，甚至严重降低系统的整体性能



### 4 CPU上下文切换（下）

#### 4.1 查看上下文切换

1. 查看系统总体情况

```bash
# 每隔5s输出一组数据
[root@VM_194_74_centos ~]# vmstat 5 5
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 118120 1188128 13137072    0    0     0    10    0    0  3  1 97  0  0
 1  0      0 117040 1188128 13137080    0    0     0    22 1071 1311  1  0 99  0  0
 0  0      0 116824 1188128 13137092    0    0     0    13 1181 1421  1  0 99  0  0
 0  0      0 117328 1188128 13137100    0    0     0    12 1165 1374  1  0 99  0  0
 1  0      0 117168 1188128 13137112    0    0     0    22 1148 1391  1  0 99  0  0
```

参数：

* `cs`：context switch，每秒上下文切换的次数
* `in`：interrupt ，每秒中断的次数
* `r`：就绪队列的长度（正在运行和等待CPU的进程数）
* `b`：blocked，处于不可中断睡眠状态的进程数

2. 查看进程的详细信息

命令：pidstat

```bash
[root@VM_194_74_centos ~]# pidstat -w 5
Linux 3.10.107-1-tlinux2_kvm_guest-0049 (VM_194_74_centos)      05/07/20        _x86_64_        (8 CPU)

08:20:54      UID       PID   cswch/s nvcswch/s  Command
08:20:59        0         1      0.80      0.00  systemd
08:20:59        0         7      0.80      0.00  migration/0
08:20:59        0         9     90.40      0.00  rcu_sched
08:20:59        0        10      0.20      0.00  watchdog/0
08:20:59        0        11      0.20      0.00  watchdog/1
08:20:59        0        12      2.00      0.00  migration/1
08:20:59        0        16      0.20      0.00  watchdog/2
08:20:59        0        17      1.00      0.00  migration/2
08:20:59        0        18      0.20      0.00  ksoftirqd/2
...
```

参数：

* cswch：每秒自愿上下文切换的次数（voluntary context switch）
* nvcswch：每秒非自愿上下文切换的次数(non voluntary context switch)

> 自愿上下文切换：进程无法获取所需资源导致的上下文切换，比如I/O，内存等**系统资源不足**时发生的上下文切换
>
> 非自愿上下文切换：进程因**时间片**已到等原因，被系统强制**调度**发生的上下文切换，比如多个进程**竞争**CPU是发生的上下文切换

#### 4.2 案例分析

`sysbench`模拟多线程调度切换

##### 4.2.1 准备

> 一台Linux机器，打开三个终端

##### 4.2.2 正式实战

1. 第一个终端：运行`sysbench`

```
# 以10个线程运行5分钟的基准测试，模拟多线程切换的问题
$ sysbench --threads=10 --max-time=300 threads run
```

2. 第二个终端：运行`vmstat`

```bash
# 每隔1秒输出1组数据（需要Ctrl+C才结束）
$ vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 6  0      0 6487428 118240 1292772    0    0     0     0 9019 1398830 16 84  0  0  0
 8  0      0 6487428 118240 1292772    0    0     0     0 10191 1392312 16 84  0  0  0
```

指标观察：

* cs列：上升到39万

* r列：就绪队列长度上升到8
* in列：终端次数上升到1万
* us（user）和sy（system）列：使用率加起来100%，sy为84%，主要被内核占用

3. 查看进程情况

```bash

# 每隔1秒输出1组数据（需要 Ctrl+C 才结束）
# -w参数表示输出进程切换指标，而-u参数则表示输出CPU使用指标
$ pidstat -w -u 1
08:06:33      UID       PID    %usr %system  %guest   %wait    %CPU   CPU  Command
08:06:34        0     10488   30.00  100.00    0.00    0.00  100.00     0  sysbench
08:06:34        0     26326    0.00    1.00    0.00    0.00    1.00     0  kworker/u4:2

08:06:33      UID       PID   cswch/s nvcswch/s  Command
08:06:34        0         8     11.00      0.00  rcu_sched
08:06:34        0        16      1.00      0.00  ksoftirqd/1
08:06:34        0       471      1.00      0.00  hv_balloon
08:06:34        0      1230      1.00      0.00  iscsid
08:06:34        0      4089      1.00      0.00  kworker/1:5
08:06:34        0      4333      1.00      0.00  kworker/0:3
08:06:34        0     10499      1.00    224.00  pidstat
08:06:34        0     26326    236.00      0.00  kworker/u4:2
08:06:34     1000     26784    223.00      0.00  sshd
```

**分析**：CPU 使用率的升高果然是 sysbench 导致的，它的 CPU 使用率已经达到了 100%。但上下文切换则是来自其他进程，包括非自愿上下文切换频率最高的 pidstat  ，以及自愿上下文切换频率最高的内核线程 kworker 和 sshd

**注意**：pidstat 输出的上下文切换次数，加起来也就几百，比 vmstat 的 139 万明显小了太多？

4. 查看线程的情况

可以看到，sysbench 进程（也就是主线程）的上下文切换次数看起来并不多，但它的子线程的上下文切换次数却有很多。上下文切换罪魁祸首，还是过多的 sysbench 线程

```bash
# 每隔1秒输出一组数据（需要 Ctrl+C 才结束）
# -wt 参数表示输出线程的上下文切换指标
$ pidstat -wt 1
08:14:05      UID      TGID       TID   cswch/s nvcswch/s  Command
...
08:14:05        0     10551         -      6.00      0.00  sysbench
08:14:05        0         -     10551      6.00      0.00  |__sysbench
08:14:05        0         -     10552  18911.00 103740.00  |__sysbench
08:14:05        0         -     10553  18915.00 100955.00  |__sysbench
08:14:05        0         -     10554  18827.00 103954.00  |__sysbench
...
```

5. 查看中断升高的原因

根据 [4.1节](# 4.1 查看上下文切换) 的分析，终端次数也升高到了1万左右，从/proc/interrupts只读文件查看中断情况

```bash
# -d 参数表示高亮显示变化的区域
$ watch -d cat /proc/interrupts
           CPU0       CPU1
...
RES:    2450431    5279697   Rescheduling interrupts
...
```

观察发现，变化速度最快的是**重调度中断（RES）**，它代表唤醒空闲状态的 CPU 来调度新的任务运行，这是在多处理器系统（SMP）中，调度器用来分散任务到不同 CPU 的机制，通常也被称为**处理器间中断**（Inter-Processor Interrupts，IPI）

**分析**：过多任务导致了重调度中断的升高，和前面分析结果一致

#### 4.3 每秒上下文切换多少次正常？

**上下文切换次数取决于系统本身的CPU性能**。如果系统的上下文切换次数比较稳定，那么从数百到一万以内，都应该算是正常的。但当上下文切换次数超过一万次，或者切换次数出现数量级的增长时，就很可能已经出现了性能问题，这时根据具体上下文切换的类型具体分析：

* 自愿上下文切换变多了，说明进程都在等待资源，有可能发生了 I/O 等其他问题
* 非自愿上下文切换变多了，说明进程都在被强制调度，也就是都在争抢 CPU，说明 CPU 的确成了瓶颈
* 中断次数变多了，说明 CPU 被中断处理程序占用，还需要通过查看 /proc/interrupts 文件来分析具体的中断类型



### 5 系统出现大量不可中断进程和僵尸进程怎么办？

#### 5.1 进程状态

* **R**：表示正在就绪队列中的进程，正在运行或者正在等待运行
* **D**：Disk Sleep，不可中断状态睡眠（Uninterruptible Sleep），一般是进程和硬件交互，并且交互过程不允许其他进程或中断打断
* **Z** ：Zombie 的缩写，它表示僵尸进程，也就是进程实际上已经结束了，但是父进程还没有回收它的资源（比如进程的描述符、PID 等）
* **S** ：Interruptible Sleep 的缩写，也就是可中断状态睡眠，表示进程因为等待某个事件而被系统挂起。当进程等待的事件发生时，它会被唤醒并进入 R 状态
* **I**： Idle 的缩写，也就是空闲状态，用在**不可中断睡眠的内核线程**上。前面说了，硬件交互导致的不可中断进程用 D 表示，但对某些内核线程来说，它们有可能实际上并没有任何负载，用 Idle 正是为了区分这种情况。要注意，D 状态的进程会导致平均负载升高， I 状态的进程却不会
* **T**：Stopped或者Traced，表示进程处于暂停或者跟踪状态（SIGSTOP信号会让进程变为暂停状态，再发送SIGCONT信号，进程又会恢复运行）
* **X**：Dead，表示进程已经消亡，top或者ps看不到

>  不可中断状态，是为了保证进程数据与硬件状态一致，正常情况下，不可中断状态在很短时间内就会结束。短时的不可中断状态进程，我们一般可以忽略。
>
> 但如果系统或硬件发生了故障，进程可能会在不可中断状态保持很久，甚至导致系统中出现大量不可中断进程。需要注意下，系统是不是出现了 I/O 等性能问题。

**注意**：ps查看进程状态时，会有Ss+，D+等情况，其中s表示进程是会话的领导进程，+表示前台进程组



#### 5.2 案例分析

##### 5.2.1 指标分析

1. 运行案例的docker

```bash
docker run --privileged --name=app -itd feisky/app:iowait
```

2. top查看指标

```bash
# 按下数字 1 切换到所有 CPU 的使用情况，观察一会儿按 Ctrl+C 结束
$ top
top - 05:56:23 up 17 days, 16:45,  2 users,  load average: 2.00, 1.68, 1.39
Tasks: 247 total,   1 running,  79 sleeping,   0 stopped, 115 zombie
%Cpu0  :  0.0 us,  0.7 sy,  0.0 ni, 38.9 id, 60.5 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu1  :  0.0 us,  0.7 sy,  0.0 ni,  4.7 id, 94.6 wa,  0.0 hi,  0.0 si,  0.0 st
...

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 4340 root      20   0   44676   4048   3432 R   0.3  0.0   0:00.05 top
 4345 root      20   0   37280  33624    860 D   0.3  0.0   0:00.01 app
 4344 root      20   0   37280  33624    860 D   0.3  0.4   0:00.01 app
    1 root      20   0  160072   9416   6752 S   0.0  0.1   0:38.59 systemd
...
```

3. 分析

* 第一行的平均负载（ Load Average），过去 1 分钟、5 分钟和 15 分钟内的平均负载在依次减小，说明平均负载正在升高；而 1 分钟内的平均负载已经达到系统的 CPU 个数，说明系统很可能已经有了性能瓶颈。
* 第二行的 Tasks，有 1 个正在运行的进程，但僵尸进程比较多，而且还在不停增加，说明有子进程在退出时没被清理。
*  CPU 的使用率情况，用户 CPU 和系统 CPU 都不高，但 iowait 分别是 60.5% 和 94.6%，好像有点儿不正常。
* 最后再看每个进程的情况， CPU 使用率最高的进程只有 0.3%，看起来并不高；但有两个进程处于 D 状态，它们可能在等待 I/O，但光凭这里并不能确定是它们导致了 iowait 升高。

4. 结论

* 第一点，iowait 太高了，导致系统的平均负载升高，甚至达到了系统 CPU 的个数
* 第二点，僵尸进程在不断增多，说明有程序没能正确清理子进程的资源。

##### 5.2.2 iowait分析

1. dstat查看系统I/O情况

```bash
# 间隔1秒输出10组数据
$ dstat 1 10
You did not select any stats, using -cdngy by default.
--total-cpu-usage-- -dsk/total- -net/total- ---paging-- ---system--
usr sys idl wai stl| read  writ| recv  send|  in   out | int   csw
  0   0  96   4   0|1219k  408k|   0     0 |   0     0 |  42   885
  0   0   2  98   0|  34M    0 | 198B  790B|   0     0 |  42   138
  0   0   0 100   0|  34M    0 |  66B  342B|   0     0 |  42   135
  0   0  84  16   0|5633k    0 |  66B  342B|   0     0 |  52   177
  0   3  39  58   0|  22M    0 |  66B  342B|   0     0 |  43   144
  0   0   0 100   0|  34M    0 | 200B  450B|   0     0 |  46   147
  0   0   2  98   0|  34M    0 |  66B  342B|   0     0 |  45   134
  0   0   0 100   0|  34M    0 |  66B  342B|   0     0 |  39   131
  0   0  83  17   0|5633k    0 |  66B  342B|   0     0 |  46   168
  0   3  39  59   0|  22M    0 |  66B  342B|   0     0 |  37   134
```

可以看到，每当 iowait 升高（wai）时，磁盘的读请求（read）都会很大。这说明 iowait 的升高跟磁盘的读请求有关，很可能就是磁盘读导致的

2. pidstat分析D状态的进程

```bash
# -d 展示 I/O 统计数据，-p 指定进程号，间隔 1 秒输出 3 组数据
$ pidstat -d -p 4344 1 3
06:38:50      UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
06:38:51        0      4344      0.00      0.00      0.00       0  app
06:38:52        0      4344      0.00      0.00      0.00       0  app
06:38:53        0      4344      0.00      0.00      0.00       0  app
```

* kB_rd 表示每秒读的 KB 数
*  kB_wr 表示每秒写的 KB 数
* iodelay 表示 I/O 的延迟（单位是时钟周期）。
* 它们都是 0，那就表示此时没有任何的读写，说明问题不是 4344 进程导致的。

3. pidstat查看所有进程情况

```bash
# 间隔 1 秒输出多组数据 (这里是 20 组)
$ pidstat -d 1 20
...
06:48:46      UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
06:48:47        0      4615      0.00      0.00      0.00       1  kworker/u4:1
06:48:47        0      6080  32768.00      0.00      0.00     170  app
06:48:47        0      6081  32768.00      0.00      0.00     184  app

06:48:47      UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
06:48:48        0      6080      0.00      0.00      0.00     110  app

06:48:48      UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
06:48:49        0      6081      0.00      0.00      0.00     191  app

06:48:49      UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command

06:48:50      UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
06:48:51        0      6082  32768.00      0.00      0.00       0  app
06:48:51        0      6083  32768.00      0.00      0.00       0  app

06:48:51      UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
06:48:52        0      6082  32768.00      0.00      0.00     184  app
06:48:52        0      6083  32768.00      0.00      0.00     175  app

06:48:52      UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s iodelay  Command
06:48:53        0      6083      0.00      0.00      0.00     105  app
...
```

观察一会儿可以发现，的确是 app 进程在进行磁盘读，并且每秒读的数据有 32 MB，看来就是 app 的问题。不过，app 进程到底在执行啥 I/O 操作呢？**进程想要访问磁盘，就必须使用系统调用，所以接下来，重点就是找出  app 进程的系统调用**

4. strace跟踪进程

```bash
$ strace -p 6082
strace: attach: ptrace(PTRACE_SEIZE, 6082): Operation not permitted
```

* 检查一下进程的状态，已经变成僵尸进程

```bash
$ ps aux | grep 6082
root      6082  0.0  0.0      0     0 pts/0    Z+   13:43   0:00 [app] <defunct>
```

5. 动态追踪

```bash
$ perf record -g
$ perf report
```

如下图，swapper是内核的调度进程，可忽略

可以发现， app 的确在通过系统调用 **sys_read()** 读取数据。并且从 new_sync_read 和 blkdev_direct_IO  能看出，进程正在对磁盘进行**直接读**，也就是**绕过了系统缓存**，每个读请求都会从磁盘直接读，这就可以解释我们观察到的 iowait 升高了

![img](https://static001.geekbang.org/resource/image/21/a1/21e79416e946ed049317a4b4c5a576a1.png)

6. 直接查看docker内代码

打开app.py文件，可以看到使用了 O_DIRECT 选项打开磁盘

```python
open(disk, O_RDONLY|O_DIRECT|O_LARGEFILE, 0755)
```

> 直接读写磁盘，对 I/O 敏感型应用（比如数据库系统）是很友好的，因为你可以在应用中，直接控制磁盘的读写。但在大部分情况下，我们最好还是通过系统缓存来优化磁盘 I/O

7. 修复代码

修复后的文件名app-fix1.py，运行docker如下

```
# 首先删除原来的应用
$ docker rm -f app
# 运行新的应用
$ docker run --privileged --name=app -itd feisky/app:iowait-fix1
```

top检查

```bash
$ top
top - 14:59:32 up 19 min,  1 user,  load average: 0.15, 0.07, 0.05
Tasks: 137 total,   1 running,  72 sleeping,   0 stopped,  12 zombie
%Cpu0  :  0.0 us,  1.7 sy,  0.0 ni, 98.0 id,  0.3 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu1  :  0.0 us,  1.3 sy,  0.0 ni, 98.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
...

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 3084 root      20   0       0      0      0 Z   1.3  0.0   0:00.04 app
 3085 root      20   0       0      0      0 Z   1.3  0.0   0:00.04 app
    1 root      20   0  159848   9120   6724 S   0.0  0.1   0:09.03 systemd
    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd
    3 root      20   0       0      0      0 I   0.0  0.0   0:00.40 kworker/0:0
...
```

##### 5.2.3 僵尸进程分析

> 僵尸进程是因为父进程没有回收子进程的资源而出现的，那么，就需要找出父进程，然后在父进程里解决。

1. pstree

```bash
# -a 表示输出每个程序完整的命令（包含路径，参数或是常驻服务的标示）
# p指定PID
# s表示显示指定进程的父进程
$ pstree -aps 3084
systemd,1
  └─dockerd,15006 -H fd://
      └─docker-containe,15024 --config /var/run/docker/containerd/containerd.toml
          └─docker-containe,3991 -namespace moby -workdir...
              └─app,4009
                  └─(app,3084)
```

2. 查看app-fix1.py代码

```python
int status = 0;
  for (;;) {
    for (int i = 0; i < 2; i++) {
      if(fork()== 0) {
        sub_process();
      }
    }
    sleep(5);
  }

  while(wait(&status)>0);
```

可以发现，文件错误地把 wait() 放到了 for 死循环的外面，也就是说，wait() 函数实际上并没被调用到，我们把它挪到 for 循环的里面就可以了。

修改后的文件我放到了 app-fix2.c ，运行对应的docker

```bash
# 先停止产生僵尸进程的 app
$ docker rm -f app
# 然后启动新的 app
$ docker run --privileged --name=app -itd feisky/app:iowait-fix2
```

3. top查看

   僵尸进程（Z 状态）没有了， iowait 也是 0，问题解决

```bash

$ top
top - 15:00:44 up 20 min,  1 user,  load average: 0.05, 0.05, 0.04
Tasks: 125 total,   1 running,  72 sleeping,   0 stopped,   0 zombie
%Cpu0  :  0.0 us,  1.7 sy,  0.0 ni, 98.3 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
%Cpu1  :  0.0 us,  1.3 sy,  0.0 ni, 98.7 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st
...

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
 3198 root      20   0    4376    840    780 S   0.3  0.0   0:00.01 app
    2 root      20   0       0      0      0 S   0.0  0.0   0:00.00 kthreadd
    3 root      20   0       0      0      0 I   0.0  0.0   0:00.41 kworker/0:0
...
```



### 6 怎么理解CPU软中断

> 中断是一种异步的事件处理机制，可以提高系统的并发处理能力
>
> 为了减少对正常进程运行调度的影响，中断处理程序应该尽快完成

#### 6.1 软中断

中断过程分为上半部和下半部：

* 上半部：用来快速处理中断，它在中断禁止模式下运行，主要处理和**硬件紧密相关**或者**时间敏感**的工作
* 下半部：用来延迟处理上半部未完成的工作，通常以**内核线程**的形式运行

网卡接收数据包的例子：网卡接收到数据包后，会通过硬件中断的方式，通知内核有新的数据到了。对上半部来说，既然是快速处理，其实就是要把网卡的数据**读到内存**中，然后**更新硬件寄存器的状态**（表示数据已经读好了），最后再发送一个软中断信号，通知下半部做进一步的处理。而下半部被软中断信号唤醒后，需要从内存中找到网络数据，再按照**网络协议栈**，对数据进行**逐层解析和处理**，直到把它送给应用程序。

可以理解为：**上半部快速执行，下半部延迟执行**

#### 6.2 查看软中断和内核线程

1. 查看/proc文件系统

* /proc/softirqs，提供了软中断的运行情况
* /proc/interrupts，提供了硬中断的运行情况

```bash
# 可以看到各类软中断在不同CPU上累积的运行次数
$ cat /proc/softirqs
                    CPU0       CPU1
          HI:          0          0
       TIMER:     811613    1972736
      NET_TX:         49          7
      NET_RX:    1136736    1506885
       BLOCK:          0          0
    IRQ_POLL:          0          0
     TASKLET:     304787       3691
       SCHED:     689718    1897539
     HRTIMER:          0          0
         RCU:    1330771    1354737
```

**注意**：

* 软中断的类型：第一列的内容，对应软中断的类型，比如**NET_TX代表网络接收中断，NET_RX代表网络发送中断，SCHE代表调度，TIMER代表定时器**等等
* 每种软中断在不同CPU上的运行情况：同一行的内容，正常情况下，同一种中断在不同CPU上的累计次数应该差不多，比如NET_RX。 而TASKLET只在调用它的函数所在的CPU运行（存在的**问题**：由于只在一个 CPU 上运行导致的调度不均衡，或者因为不能在多个 CPU 上并行运行带来了性能限制）

2. 软中断以内核线程方式运行，每个CPU都对应一个软中断内核线程（ksoftirqd/CPU编号）

```bash
$ ps aux | grep softirq
root         7  0.0  0.0      0     0 ?        S    Oct10   0:01 [ksoftirqd/0]
root        16  0.0  0.0      0     0 ?        S    Oct10   0:01 [ksoftirqd/1]
```



### 7 系统的软中断CPU使用率升高，该怎么办？

#### 7.1 案例准备

工具介绍：

* sar 是一个系统活动报告工具，既可以实时查看系统的当前活动，又可以配置保存和报告历史统计数据。
* hping3 是一个可以构造 TCP/IP 协议数据包的工具，可以对系统进行安全审计、防火墙测试等。
* tcpdump 是一个常用的网络抓包工具，常用来分析各种网络问题

案例图示

<img src="https://static001.geekbang.org/resource/image/5f/96/5f9487847e937f955ebc2ec86d490b96.png" width="600">

其中一台虚拟机运行 Nginx ，用来模拟待分析的 Web 服务器；而另一台当作 Web 服务器的客户端，用来给 Nginx 增加压力请求

#### 7.2 操作和分析

运行Nginx应用

```bash
# 运行Nginx服务并对外开放80端口
$ docker run -itd --name=nginx -p 80:80 nginx
```

在另一个终端运行hping3模拟客户端的请求

```bash
# -S参数表示设置TCP协议的SYN（同步序列号），-p表示目的端口为80
# -i u100表示每隔100微秒发送一个网络帧
# 注：如果你在实践过程中现象不明显，可以尝试把100调小，比如调成10甚至1
$ hping3 -S -p 80 -i u100 192.168.0.30
```

会发现简单的shell命令都变慢了，执行top查看系统整体情况

```bash
# top运行后按数字1切换到显示所有CPU
$ top
top - 10:50:58 up 1 days, 22:10,  1 user,  load average: 0.00, 0.00, 0.00
Tasks: 122 total,   1 running,  71 sleeping,   0 stopped,   0 zombie
%Cpu0  :  0.0 us,  0.0 sy,  0.0 ni, 96.7 id,  0.0 wa,  0.0 hi,  3.3 si,  0.0 st
%Cpu1  :  0.0 us,  0.0 sy,  0.0 ni, 95.6 id,  0.0 wa,  0.0 hi,  4.4 si,  0.0 st
...

  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
    7 root      20   0       0      0      0 S   0.3  0.0   0:01.64 ksoftirqd/0
   16 root      20   0       0      0      0 S   0.3  0.0   0:01.97 ksoftirqd/1
 2663 root      20   0  923480  28292  13996 S   0.3  0.3   4:58.66 docker-containe
 3699 root      20   0       0      0      0 I   0.3  0.0   0:00.13 kworker/u4:0
 3708 root      20   0   44572   4176   3512 R   0.3  0.1   0:00.07 top
    1 root      20   0  225384   9136   6724 S   0.0  0.1   0:23.25 systemd
    2 root      20   0       0      0      0 S   0.0  0.0   0:00.03 kthreadd
...
```

可以看到：

* 平均负载全是 0，就绪队列里面只有一个进程（1 running）。
* 每个 CPU 的使用率都挺低，最高的 CPU1 的使用率也只有 4.4%，并不算高。
* 再看进程列表，CPU 使用率最高的进程也只有 0.3%
* 两个 CPU 的使用率虽然分别只有 3.3% 和 4.4%，但都用在了软中断上；而从进程列表上也可以看到，CPU 使用率最高的也是软中断进程 ksoftirqd

查看软中断变化情况

```bash
$ watch -d cat /proc/softirqs
                    CPU0       CPU1
          HI:          0          0
       TIMER:    1083906    2368646
      NET_TX:         53          9
      NET_RX:    1550643    1916776
       BLOCK:          0          0
    IRQ_POLL:          0          0
     TASKLET:     333637       3930
       SCHED:     963675    2293171
     HRTIMER:          0          0
         RCU:    1542111    1590625
```

可以发现， TIMER（定时中断）、NET_RX（网络接收）、SCHED（内核调度）、RCU（RCU 锁）等这几个软中断都在不停变化，这些中断是保证 Linux 调度、时钟和临界区保护这些正常工作所必需，变化是正常的。而其中的NET_RX，也就是**网络数据包接收软中断**的变化速率最快

使用sar工具查看网络收发情况(可以观察网络收发吞吐量和PPS)

```bash
# -n DEV 表示显示网络收发的报告，间隔1秒输出一组数据
$ sar -n DEV 1
15:03:46        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
15:03:47         eth0  12607.00   6304.00    664.86    358.11      0.00      0.00      0.00      0.01
15:03:47      docker0   6302.00  12604.00    270.79    664.66      0.00      0.00      0.00      0.00
15:03:47           lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
15:03:47    veth9f6bbcd   6302.00  12604.00    356.95    664.66      0.00      0.00      0.00      0.05
```

可以发现：

* 对网卡 eth0 来说，每秒接收的网络帧数比较大，达到了 12607，而发送的网络帧数则比较小，只有 6304；每秒接收的千字节数只有 664 KB，而发送的千字节数更小，只有 358 KB。
* docker0 和 veth9f6bbcd 的数据跟 eth0 基本一致，只是发送和接收相反，发送的数据较大而接收的数据较小。这是 Linux 内部网桥转发导致的，暂且不用深究，只要知道这是系统把 eth0 收到的包转发给 Nginx 服务即可
* 重点来看 eth0 ：接收的 PPS 比较大，达到 12607，而接收的 BPS 却很小，只有 664 KB。直观来看网络帧应该都是比较小的，664*1024/12607 = 54 字节，说明平均每个网络帧只有 54 字节，这显然是很小的网络帧，也就是所谓的**小包问题**

tcpdump抓取eth0上的包，指定TCP协议和80端口

```bash
# -i eth0 只抓取eth0网卡，-n不解析协议名和主机名
# tcp port 80表示只抓取tcp协议并且端口号为80的网络帧
$ tcpdump -i eth0 -n tcp port 80
15:11:32.678966 IP 192.168.0.2.18238 > 192.168.0.30.80: Flags [S], seq 458303614, win 512, length 0
...
```

从 tcpdump 的输出中，你可以发现：

* 192.168.0.2.18238 > 192.168.0.30.80  ，表示网络帧从 192.168.0.2 的 18238 端口发送到 192.168.0.30 的 80 端口，也就是从运行 hping3 机器的 18238 端口发送网络帧，目的为 Nginx 所在机器的 80 端口。
* Flags [S] 则表示这是一个 SYN 包

**最后，可以确定这是从192.168.0.2.18238来的SYN FLOOF攻击**

SYN FLOOD 问题最简单的解决方法：从交换机或者硬件防火墙中封掉来源 IP，这样 SYN FLOOD 网络帧就不会发送到服务器中（后面的网络篇再进一步深究）

### 8 套路篇：如何迅速分析出CPU的瓶颈在哪里？

#### 8.1 CPU性能指标

性能指标总览

<img src="https://static001.geekbang.org/resource/image/1e/07/1e66612e0022cd6c17847f3ab6989007.png" width="500" height="500" align="middle">

##### 8.1.1 CPU使用率

CPU 使用率描述了非空闲时间占总 CPU 时间的百分比，根据 CPU 上运行任务的不同，又被分为用户 CPU、系统 CPU、等待 I/O CPU、软中断和硬中断等。用户 CPU 使用率，包括用户态 CPU 使用率（user）和低优先级用户态 

* CPU 使用率（nice），表示 CPU 在**用户态**运行的时间百分比。用户 CPU 使用率高，通常说明有**应用程序**比较繁忙。
* 系统 CPU 使用率，表示 CPU 在**内核态**运行的时间百分比（不包括中断）。系统 CPU 使用率高，说明**内核**比较繁忙。
* 等待 I/O 的 CPU 使用率，通常也称为 **iowait**，表示**等待 I/O** 的时间百分比。iowait 高，通常说明系统与硬件设备的 I/O 交互时间比较长。
* 软中断和硬中断的 CPU 使用率，分别表示内核调用软中断处理程序、硬中断处理程序的时间百分比。它们的使用率高，通常说明系统发生了大量的中断。
* 除了上面这些，还有在虚拟化环境中会用到的**窃取 CPU 使用率（steal）**和**客户 CPU 使用率（guest）**，分别表示被其他虚拟机占用的 CPU 时间百分比，和运行客户虚拟机的 CPU 时间百分比。

##### 8.1.2 平均负载

> 系统的平均活跃进程数。它反应了系统的整体负载情况，主要包括三个数值，分别指过去 1 分钟、过去 5 分钟和过去 15 分钟的平均负载。
>
> 理想情况下，平均负载等于逻辑 CPU 个数，这表示每个 CPU 都恰好被充分利用。如果平均负载大于逻辑 CPU 个数，就表示负载比较重了。

##### 8.1.3 进程上下文切换

进程上下文切换分为：

1. 自愿上下文切换
2. 非自愿上下文切换

**注意**：过多的上下文切换，会将原本运行进程的 CPU 时间，消耗在**寄存器、内核栈以及虚拟内存等数据的保存和恢复**上，缩短进程真正运行的时间，成为性能瓶颈

##### 8.1.4 CPU缓存命中率

CPU 缓存的速度介于 CPU 和内存之间，缓存的是**热点的内存数据**。

如下图，根据不断增长的热点数据，这些缓存按照大小不同分为 L1、L2、L3 等三级缓存，其中 L1 和 L2 常用在单核中， L3 则用在多核中。从 L1 到 L3，三级缓存的大小依次增大，相应的，性能依次降低（当然比内存还是好得多）。而它们的命中率，衡量的是 **CPU 缓存的复用情况**，命中率越高，则表示性能越好。

![img](https://static001.geekbang.org/resource/image/aa/33/aa08816b60e453b52b5fae5e63549e33.png)

#### 8.2 CPU性能工具

* 平均负载案例：使用**uptime**查看平均负载，在平均负载升高时，使用**mpstat**和**pidstat**分别观察每个CPU和每个进程CPU的使用情况，找到导致平均负载升高的stress进程
* 上下文切换的案例：先使用**vmstat**，查看系统的上下文切换次数和中断次数；然后通过**pidstat**（-w参数）观察进程的自愿上下文切换和非自愿上下文切换；最后通过**vmstat**（-wt参数）查看线程的上下文切换情况，从而找到了线程上下文切换增多的原因是sysbench工具
* 进程CPU使用率升高的案例：先使用top找出系统和进程CPU的使用情况，发现了CPU使用率很高的进程php-fpm，再使用perf top找出热点函数sqrt()；如果是Python应用，可以使用profiler工具**pyflame**对指定进程分析（pyflame -p pid --threads -s 检测时间 -r 取样间隔 -o <file.txt>），再通过flamegraph.pl将输出的txt文件转换为*.svg格式的火焰图（./flamegraph.pl prof.txt > prof.svg）
* 不可中断进程和僵尸进程的案例：
  * 不可中断进程分析过程：先使用top查看，发现存在D状态（不可中断休眠进程）和Z状态（僵尸进程），并且iowait较高；使用**dstat**分析磁盘I/O，发现**app**进程有大量的磁盘读请求；使用**pidstat**(-d -p 参数)分析app进程的I/O操作，发现没有大量的I/O操作，再用pidstat -d分析系统的I/O情况，发现还是app进程在进行磁盘读；再使用**strace**跟踪D状态进程对应进程号的系统调用，发现没有权限；ps查看发现对应进程号的进程已经变成僵尸进程；之后，通过perf record -g和perf report生成报告，查看app进程的调用栈，发现CPU使用主要是在sys_read()函数，定位到是在对磁盘进行直接读（direct_IO）；查看代码发现open()系统调用使用了O_DIRECT参数
  * 僵尸进程分析：使用pstree命令找出僵尸进程的父进程是app进程，然后查看app.c文件，发现wait()使用位置不当导致不能回收子进程
* 软中断的案例：先使用top查看系统指标，发现系统CPU使用率很低，但是主要是在软中断si上，然后查看/proc/softirqs查看系统软中断变化情况，发现NET_RX变化率很快，再使用sar工具查看系统的网络收发情况，发现eth0网卡接收到了大量的小包；在通过抓包工具tcpdump，发现eth0接受到了大量的SYN包，最终确定了是SYN FLOOD攻击

##### 8.2.1 性能指标找工具

<img src="https://static001.geekbang.org/resource/image/59/ec/596397e1d6335d2990f70427ad4b14ec.png" width="600" height="800">

##### 8.2.2 工具找指标

<img src="https://static001.geekbang.org/resource/image/b0/ca/b0c67a7196f5ca4cc58f14f959a364ca.png" width="600" height="600">

#### 8.3 如何分析CPU的性能瓶颈

**重点**：弄清楚性能指标之间的关联性

<img src="https://static001.geekbang.org/resource/image/7a/17/7a445960a4bc0a58a02e1bc75648aa17.png" width="600">

### 9 CPU性能优化的几个思路

#### 9.1 性能优化方法论

确定三个问题：

* 判断所做的性能优化是否有效？优化后，能提升多少性能，有多少收益？
* 如果有多个性能问题同时存在，应该先优化哪一个？
* 当有多种优化的方法，应该选择哪一种？

##### 9.1.1 怎么评估性能优化的效果

**三步走**的原则：

1. 确定性能的量化指标
2. 测试优化前的性能指标
3. 测试优化后的性能指标

**第一步**，性能的量化指标包括CPU使用率、应用的吞吐量、响应时间等等，**不要局限在单一维度的指标上**。例如，以Web应用为例：

* 应用程序的维度，使用**吞吐量和请求延时**来评估
* 系统资源的维度，使用**CPU使用率**来评估

好的应用程序是性能优化的最终结果和目的，要使用应用程序的指标，来评估性能优化的整体效果；而系统资源的使用情况是影响应用程序的根源，需要用资源的指标，来分析应用性能的瓶颈来源

**第二三步**，对比第一步确定的**量化指标**在优化前后的差距，拿数据说话。例如，使用ab工具测试Web应用的并发请求数和响应延时，同时使用vmstat,pidstat等工具，观察系统和进程的CPU使用率，同时获得了应用和系统两个维度的性能指标

**进行性能测试需要注意的是**：

* 要避免性能测试工具干扰应用程序的性能
* 避免外部环境的变化影响性能指标的评估。在优化前、后的应用程序，都运行在相同配置的机器上，并且它们的外部依赖也要完全一致

##### 9.1.2 多个性能问题同时存在，怎么选择？

遵循**二八原则**，80%的性能问题都是由于20%的代码导致的，**并不是所有的性能问题都值得优化**

分析的步骤：

* 挨个分析出所有的性能瓶颈，排除掉有因果关系的性能问题
* 在剩下的几个性能问题中，选择能明显提升应用性能的问题进行修复，有两种方法：
  * 如果系统资源出现瓶颈，首先优化系统资源使用的问题
  * 针对不同类型的指标，，首先优化导致**性能指标变化幅度最大**的那些瓶颈问题

##### 9.1.3 有多种优化方法时，如何选择？

**性能优化并非没有成本**。

一个很典型的例子网络中的 DPDK（Data Plane Development Kit）。DPDK 是一种优化网络处理速度的方法，它通过绕开内核网络协议栈的方法，提升网络的处理能力。不过它有一个很典型的要求，就是要**独占一个 CPU 以及一定数量的内存大页**，并且总是以 100% 的 CPU 使用率运行。所以，如果你的 CPU 核数很少，就有点得不偿失了。

因此，在考虑性能优化方法时，要结合实际情况，考虑多方面的因素，进行权衡在做选择

#### 9.2 CPU优化

##### 9.2.1 应用程序优化

常见的几种优化方法：

* **编译器优化**：很多编译器都会提供优化选项，适当开启它们，在编译阶段你就可以获得编译器的帮助，来提升性能。比如， gcc 就提供了优化选项 -O2，开启后会自动对应用程序的代码进行优化。
* **算法优化**：使用复杂度更低的算法，显著加快处理速度
* **异步处理**：使用异步处理，可以避免程序因为等待某个资源而一直阻塞，从而提升程序的并发处理能力。比如，把轮询替换为事件通知，就可以避免轮询耗费 CPU 的问题。
* **多线程代替多进程**：前面讲过，相对于进程的上下文切换，线程的上下文切换并不切换进程地址空间，因此可以降低上下文切换的成本。
* **善用缓存**：经常访问的数据或者计算过程中的步骤，可以放到内存中缓存起来，这样在下次用时就能直接从内存中获取，加快程序的处理速度。

##### 9.2.2 系统优化

常见的系统优化方法：

* **CPU 绑定**：把进程绑定到一个或者多个 CPU 上，可以提高 CPU 缓存的命中率，减少跨 CPU 调度带来的上下文切换问题
* **CPU 独占**：跟 CPU 绑定类似，进一步将 CPU 分组，并通过 CPU 亲和性机制为其分配进程。这样，这些 CPU 就由指定的进程独占，换句话说，不允许其他进程再来使用这些 CPU
* **优先级调整**：使用 nice 调整进程的优先级，正值调低优先级，负值调高优先级。可以适当降低非核心应用的优先级，增高核心应用的优先级，可以确保核心应用得到优先处理
* **为进程设置资源限制**：使用 Linux cgroups  来设置进程的 CPU 使用上限，可以防止由于某个应用自身的问题，而耗尽系统资源。
* **NUMA（Non-Uniform Memory Access）优化**：支持 NUMA 的处理器会将内存划分为多个 node，每个 node 关联到系统的一个处理器。NUMA 优化，其实就是让 CPU 尽可能只访问本地内存。
* **中断负载均衡**：无论是软中断还是硬中断，它们的中断处理程序都可能会耗费大量的 CPU。开启 irqbalance 服务或者配置 smp_affinity，就可以把**中断处理过程自动负载均衡到多个 CPU 上**。

##### 9.2.3 避免过早优化

性能优化最好是**逐步完善，动态进行，不追求一步到位**，而要**首先保证能满足当前的性能要求**。当发现性能不满足要求或者出现性能瓶颈时，再根据性能评估的结果，选择最重要的性能问题进行优化

#### 9.3 总结

**要忍住“把 CPU 性能优化到极致”的冲动**，因为 CPU 并不是唯一的性能因素，还会有其他的性能问题，比如内存、网络、I/O 甚至是架构设计的问题。

如果不做全方位的分析和测试，只是单纯地把某个指标提升到极致，并不一定能带来整体的收益。

## 内存性能篇

### 10 Linux内存工作原理

#### 10.1 内存分配与回收

malloc() 是 C 标准库提供的内存分配函数，对应到系统调用上，有两种实现方式，即 brk() 和 mmap()

对小块内存（小于 128K），C 标准库使用 brk() 来分配，也就是通过移动堆顶的位置来分配内存。这些内存释放后并不会立刻归还系统，而是被缓存起来，这样就可以重复使用。

对大块内存（大于 128K），则直接使用内存映射 mmap() 来分配，也就是在文件映射段找一块空闲内存分配出去

各自的**优缺点**：

* brk() 方式的缓存，可以减少缺页异常的发生，提高内存访问效率；不过，由于这些内存没有归还系统，在内存工作繁忙时，频繁的内存分配和释放会造成内存碎片
* mmap() 方式分配的内存，会在释放时直接归还系统，所以每次 mmap 都会发生缺页异常。在内存工作繁忙时，频繁的内存分配会导致大量的缺页异常，使内核的管理负担增大

整体来说，Linux 使用**伙伴系统**来管理内存分配。前面我们提到过，这些内存在 MMU 中以页为单位进行管理，伙伴系统也一样，以页为单位来管理内存，并且会通过相邻页的合并，减少内存碎片化（比如 brk 方式造成的内存碎片）

在用户空间，malloc 通过 brk() 分配的内存，在释放时并不立即归还系统，而是缓存起来重复利用。在内核空间，Linux 通过 slab 分配器来管理小内存，可以把 slab 看成构建在**伙伴系统上的一个缓存**，主要作用就是分配并释放内核中的小对象

系统也不会任由某个进程用完所有内存。在发现内存紧张时，系统就会通过一系列机制来回收内存：

* 回收缓存，比如使用 LRU（Least Recently Used）算法，回收最近使用最少的内存页面
* 回收不常访问的内存，把不常用的内存通过交换分区直接写到磁盘中（会用到交换分区）
* 杀死进程，内存紧张时系统还会通过 OOM（Out of Memory），直接杀掉占用大量内存的进程

OOM是内核的一种保护机制。它监控进程的内存使用情况，并且使用 oom_score 为每个进程的内存使用情况进行评分：

* 进程消耗的内存越大，oom_score 就越大
* 进程运行占用的 CPU 越多，oom_score 就越小

可以手动设置进程的oom_adj来调整oom_score。oom_adj的范围是[-17, 15]，数值越大，进程越容易被OOM杀死；反之，越不容易被OOM杀死

#### 10.2 如何查看内存使用情况

1. `free`命令

```bash
# 注意不同版本的free输出可能会有所不同
$ free
              total        used        free      shared  buff/cache   available
Mem:        8169348      263524     6875352         668     1030472     7611064
Swap:             0           0           0
```

* 第一列，total 是总内存大小；
* 第二列，used 是已使用内存的大小，包含了共享内存；
* 第三列，free 是未使用内存的大小；
* 第四列，shared 是共享内存的大小；
* 第五列，buff/cache 是缓存和缓冲区的大小；
* 最后一列，available 是新进程可用内存的大小

**注意**：available 不仅包含未使用内存，还包括了可回收的缓存，所以一般会比未使用内存更大。不过，并不是所有缓存都可以回收，因为有些缓存可能正在使用中

2. `top`命令

可以查看每个进程的内存使用情况

```bash
# 按下M切换到内存排序
$ top
...
KiB Mem :  8169348 total,  6871440 free,   267096 used,  1030812 buff/cache
KiB Swap:        0 total,        0 free,        0 used.  7607492 avail Mem


  PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND
  430 root      19  -1  122360  35588  23748 S   0.0  0.4   0:32.17 systemd-journal
 1075 root      20   0  771860  22744  11368 S   0.0  0.3   0:38.89 snapd
 1048 root      20   0  170904  17292   9488 S   0.0  0.2   0:00.24 networkd-dispat
    1 root      20   0   78020   9156   6644 S   0.0  0.1   0:22.92 systemd
12376 azure     20   0   76632   7456   6420 S   0.0  0.1   0:00.01 systemd
12374 root      20   0  107984   7312   6304 S   0.0  0.1   0:00.00 sshd
...
```

主要的几个信息：

* VIRT 是**进程虚拟内存**的大小，只要是进程申请过的内存，即便还没有真正分配物理内存，也会计算在内
* RES 是**常驻内存**的大小，也就是进程**实际使用的物理内存**大小，但**不包括 Swap 和共享内存**
* SHR 是共享内存的大小，比如与其他进程共同使用的共享内存、加载的动态链接库以及程序的代码段等
* %MEM 是进程使用物理内存占系统总内存的百分比

**注意**：

* 虚拟内存通常并不会全部分配物理内存。从上面的输出，你可以发现每个进程的虚拟内存都比常驻内存大得多
* 共享内存 SHR 并不一定是共享的，比方说，**程序的代码段、非共享的动态链接库**，也都算在 SHR 里。SHR 也包括了**进程间真正共享的内存**。所以在计算多个进程的内存使用时，不要把所有进程的 SHR 直接相加得出结果

### 11 内存的Buffer和Cache

#### 11.1 free的数据来源

man free查看

![image-20200705165658500](D:\Tech\学习笔记\Linux学习笔记\image-20200705165658500.png)

从手册看到：

* Buffers 是内核缓冲区用到的内存，对应的是  /proc/meminfo 中的 Buffers 值
* Cache 是内核页缓存和 Slab 用到的内存，对应的是  /proc/meminfo 中的 Cached 与 Slab之和

#### 11.2 proc文件系统

man proc

![image-20200705170712936](D:\Tech\学习笔记\Linux学习笔记\image-20200705170712936.png)

![image-20200705171053845](D:\Tech\学习笔记\Linux学习笔记\image-20200705171053845.png)

通过文档可以看到：

* Buffers 是对原始磁盘块的临时存储，也就是用来缓存磁盘的数据，通常不会特别大（20MB 左右）。这样，内核就可以把分散的写集中起来，统一优化磁盘的写入，比如可以把多次小的写合并成单次大的写等等。
* Cached 是从磁盘读取文件的页缓存，也就是用来缓存从文件读取的数据。这样，下次访问这些文件数据时，就可以直接从内存中快速获取，而不需要再次访问缓慢的磁盘
* Slab 代表内核数据结构缓存，包括两部分，其中的可回收部分，用 SReclaimable 记录；而不可回收部分，用 SUnreclaim 记录

#### 11.3 案例测试

##### 11.3.1 场景一：磁盘和文件写

运行vmstat命令

```bash
[root@VM_194_74_centos ~]# vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 14613256 131120 772856    0    0     0    16    2    1  1  1 98  0  0
 0  0      0 14612504 131120 772848    0    0     0     0 1323 1513  1  1 98  0  0
 0  0      0 14612044 131120 772824    0    0     0     0 1297 1537  1  1 98  0  0
 1  0      0 14612484 131120 772812    0    0     0     0 1229 1562  1  1 99  0  0
 0  0      0 14612252 131120 772784    0    0     0     0 1338 1571  1  1 98  0  0
 0  0      0 14612640 131120 772812    0    0     0    72 1231 1533  1  1 98  0  0
 1  0      0 14612500 131120 772828    0    0     0     0 1258 1612  1  0 98  0  0
 0  0      0 14612568 131120 772840    0    0     0     0 1241 1579  1  1 98  0  0
 0  0      0 14612676 131124 772848    0    0     0   164 1247 1506  1  1 98  0  0
 1  0      0 14612908 131132 772800    0    0     0    28 1284 1517  1  1 98  0  0
 0  0      0 14612396 131132 772804    0    0     0     0 1257 1517  1  1 98  0  0
 0  0      0 14612264 131132 772784    0    0     0     0 1236 1497  1  1 98  0  0
```

* buff 和 cache 就是我们前面看到的 Buffers 和 Cache，单位是 KB
* bi 和 bo 则分别表示块设备读取和写入的大小，单位为块 / 秒。因为 Linux 中块的大小是 1KB，所以这个单位也就等价于 KB/s

在另一终端执行dd命令通过读取随机设备，生成一个 500MB 大小的文件

```bash
dd if=/dev/urandom of=/data/file bs=1M count=500
```

继续观察buff和cache的变化如下

```bash
[root@VM_194_74_centos /tmp]# vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 3  0      0 14519588 141424 853684    0    0     0    16    2    1  1  1 98  0  0
 1  0      0 14508040 141428 864424    0    0     0    56 2358 2068  1 14 85  0  0
 3  1      0 14495872 141440 875812    0    0     0   816 2290 2160  1 13 85  1  0
 2  0      0 14487364 141564 886348    0    0     0  1652 2837 3160  0 13 85  2  0
 1  0      0 14477220 141644 896736    0    0     0  2040 3100 3700  1 13 83  2  0
 1  0      0 14465036 141744 908372    0    0     0  1440 2903 2931  2 13 83  2  0
 1  0      0 14454148 141936 918752    0    0     0  2088 3608 4388  1 13 83  3  0
 1  0      0 14442756 142124 930444    0    0     0  1848 3596 4150  1 14 83  3  0
 ...
 2  1      0 14273756 143756 1097612    0    0     0  1896 3653 4056  1 13 83  3  0
 2  1      0 14261684 143796 1109212    0    0     0  1932 3229 3276  1 13 83  3  0
 1  1      0 14250692 143880 1119576    0    0     0  1572 3168 3173  1 13 83  2  0
 4  1      0 14236556 143928 1131176    0    0     0  1684 3120 3054  0 13 84  2  0
 1  0      0 14228684 144008 1141704    0    0     0  2336 3421 3446  1 13 83  3  0
 1  0      0 14218020 144076 1153268    0    0     0  2044 3590 3837  1 13 83  3  0
 2  0      0 14206820 144244 1164052    0    0     8 105372 3650 3916  1 13 82  3  0
 0  2      0 14197416 144316 1173492    0    0     4 152984 3821 4611  1 13 69 17  0
 1  1      0 14187000 144392 1184100    0    0     0 138236 3805 4367  1 12 72 15  0
 1  0      0 14175248 144468 1194476    0    0     0  2032 3816 4080  1 13 82  4  0
```

可以看到：

* 在 dd 命令运行时， Cache 在不停地增长，而 Buffer 基本保持不变
* 当 dd 命令结束后，Cache 不再增长，但块设备写还会持续一段时间，并且，多次 I/O 写的结果加起来，才是 dd 要写的 500M 的数据

同样的，使用dd命令进行磁盘写入(由于需要系统配置多块磁盘，并且磁盘分区 /dev/sdb1 还要处于未使用状态，没有实际操作)

```bash
 dd if=/dev/urandom of=/dev/sdb1 bs=1M count=2048
```

可以看到，**写磁盘用到了大量的 Buffer**

##### 11.3.2 场景二：磁盘和文件读

运行文件读的命令如下

```bash
# 文件读
dd if=/tmp/file of=/dev/null
```

```bash
[root@VM_194_74_centos /tmp]# vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  0      0 15026816    916 487588    0    0     0    17    3    1  1  1 98  0  0
 0  0      0 15024456   1304 488564    0    0  1736     0 1469 1738  1  1 97  0  0
 0  0      0 15023804   1312 489356    0    0     0    88 1240 1515  1  1 98  0  0
 1  0      0 14913544   1316 600244    0    0 111040     0 2174 3221  1  2 93  4  0
 0  1      0 14753816   1320 759112    0    0 159364     0 2515 3853  2  2 86 10  0
 1  0      0 14600624   1320 912268    0    0 152704     0 2494 3843  1  2 86 10  0
 0  0      0 14511172   1320 1001580    0    0 89008     0 2019 2887  1  2 91  6  0
 1  0      0 14511452   1324 1001532    0    0     4     0 1215 1414  1  1 98  0  0
 1  0      0 14512776   1332 1001544    0    0     0   100  978  977  0  0 99  0  0
 0  0      0 14512776   1332 1001528    0    0     0     0 1248 1501  1  1 98  0  0
 0  0      0 14512272   1332 1001552    0    0     0     0 1306 1521  1  1 98  0  0
```

运行磁盘读的命令如下

```bash
# 磁盘度
dd if=/dev/sda1 of=/dev/null bs=1M count=1024
```

```bash
[root@VM_194_74_centos /tmp]# vmstat 1
procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----
 r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st
 1  1      0 15016116   7920 490748    0    0     0    17    3    1  1  1 98  0  0
 0  0      0 15014992   8816 490736    0    0     0  1960 2577 4077  1  1 96  3  0
 0  1      0 15012224   9812 492796    0    0  2060  2224 2745 4192  1  1 94  3  0
 0  0      0 15010188  10748 493040    0    0     4  1984 2423 3921  1  1 96  3  0
 0  2      0 14814940 200276 497868    0    0 188992  1912 3979 6307  1  2 87 10  0
 1  2      0 14656116 355108 501324    0    0 153856  1508 3356 5470  1  2 86 11  0
 2  2      0 14495260 509548 505376    0    0 153600  1772 3275 5219  1  2 86 11  0
 1  1      0 14339432 664144 509788    0    0 153856  1564 3228 5322  0  2 87 11  0
 1  1      0 14171264 828176 513820    0    0 163072  2100 3983 6555  1  2 86 11  0
 0  1      0 14012056 984016 517804    0    0 154880  2112 4066 6601  1  2 86 11  0
 0  0      0 13928396 1065744 520012    0    0 80672  2436 3445 5497  1  1 90  7  0
 0  0      0 13928432 1066576 520244    0    0     0  1876 2521 3985  1  1 96  2  0
 1  1      0 13924696 1068660 520500    0    0     0  4488 3529 5999  2  1 91  6  0
```

可以看到，读取文件时（也就是 bi 大于 0 时），Buffer 保持不变，而 Cache 则在不停增长；而读取磁盘时，Cache保持不变，Buffer不断增长

#### 11.4 结论

**Buffer 是对磁盘数据的缓存，而 Cache 是文件数据的缓存，它们既会用在读请求中，也会用在写请求中**



### 12 案例篇：如何利用系统缓存优化程序的运行效率



### 13 案例篇：内存泄漏该如何定位和处理



### 14 系统的Swap机制

**文件页**：代表可回收内存，文件页的大部分可以直接回收，以后有需要时，再从磁盘重新读取；而那些被应用程序修改过，并且暂时还没写入磁盘的数据（也就是脏页），就得先写入磁盘，然后才能进行内存释放

脏页一般以两种方式写入磁盘：

* 在应用程序中，通过系统调用 fsync  ，把脏页同步到磁盘中
* 由内核线程 pdflush 负责这些脏页的刷新

**匿名页**：应用程序动态分配的**堆内存**，使用Swap机制回收

#### 14.1 Swap原理

Swap 简单来说就是把一块磁盘空间或者一个本地文件，当成内存来使用。它包括**换出和换入**两个过程。

* 换出，就是把进程暂时不用的内存数据存储到磁盘中，并释放这些数据占用的内存
* 换入，则是在进程再次访问这些内存的时候，把它们从磁盘读到内存中来

常见的笔记本电脑的休眠和快速开机的功能，也基于 Swap 。休眠时，把系统的内存存入磁盘，这样等到再次开机时，只要从磁盘中加载内存就可以。这样就省去了很多应用程序的初始化过程，加快了开机速度

内存回收的时机：

* **直接内存回收**：当有新的大块内存分配请求，但是剩余内存不足，这个时候系统就需要回收一部分内存
* **内核线程kswapd0**来定期回收内存，它定义了三个内存阈值（watermark，也称为水位），分别是页最小阈值（pages_min）、页低阈值（pages_low）和页高阈值（pages_high）。剩余内存，则使用 pages_free 表示

![img](https://static001.geekbang.org/resource/image/c1/20/c1054f1e71037795c6f290e670b29120.png)

kswapd0 定期扫描内存的使用情况，并根据剩余内存落在这三个阈值的空间位置，进行内存的回收操作：

* 剩余内存小于页最小阈值，说明进程可用内存都耗尽了，只有内核才可以分配内存
* 剩余内存落在页最小阈值和页低阈值中间，说明内存压力比较大，剩余内存不多了。这时 kswapd0 会执行内存回收，直到剩余内存大于高阈值为止
* 剩余内存落在页低阈值和页高阈值中间，说明内存有一定压力，但还可以满足新内存请求
* 剩余内存大于页高阈值，说明剩余内存比较多，没有内存压力

**页低阈值**是由内核选项 /proc/sys/vm/min_free_kbytes 设置，其他两个阈值，都是根据页最小阈值计算生成的

#### 14.2 NUMA和Swap

在 NUMA 架构下，多个处理器被划分到不同 Node 上，且每个 Node 都拥有自己的本地内存空间。而同一个 Node 内部的内存空间，实际上又可以进一步分为不同的内存域（Zone），比如直接内存访问区（DMA）、普通内存区（NORMAL）、伪内存区（MOVABLE）等，如下图所示：

![img](https://static001.geekbang.org/resource/image/be/d9/be6cabdecc2ec98893f67ebd5b9aead9.png)

使用numactl命令查看Node的分布情况

```bash
[root@VM_194_74_centos /tmp]# numactl --hardware
available: 1 nodes (0)
node 0 cpus: 0 1 2 3 4 5 6 7
node 0 size: 16383 MB
node 0 free: 13452 MB
node distances:
node   0 
  0:  10 
```

前面提到的三个内存阈值（页最小阈值、页低阈值和页高阈值），都可以通过内存域在 proc 文件系统中的接口 /proc/zoneinfo 来查看

```bash
[root@VM_194_74_centos ~/millerxie/taskCreate]# cat /proc/zoneinfo| head -n 20
Node 0, zone      DMA
  pages free     3969
        min      3
        low      3
        high     4
        scanned  0
        spanned  4095
        present  3998
        managed  3977
    nr_free_pages 3969
    nr_inactive_anon 0
    nr_active_anon 0
    nr_inactive_file 0
    nr_active_file 0
    ...
```

主要指标包括：

* pages 处的 min、low、high，就是上面提到的三个内存阈值，而 free 是**剩余内存页数**，它跟后面的 nr_free_pages 相同。
* nr_zone_active_anon 和 nr_zone_inactive_anon，分别是**活跃和非活跃的匿名页数**
* nr_zone_active_file 和 nr_zone_inactive_file，分别是**活跃和非活跃的文件页数**

某个 Node 内存不足时，系统可以从其他 Node 寻找空闲内存，也可以从本地内存中回收内存。具体选哪种模式，你可以通过 /proc/sys/vm/zone_reclaim_mode 来调整。它支持以下几个选项：

* 默认的 0 ，也就是刚刚提到的模式，表示既可以从其他 Node 寻找空闲内存，也可以从本地回收内存
* 1、2、4 都表示只回收本地内存，2 表示可以回写脏数据回收内存，4 表示可以用 Swap 方式回收内存

#### 14.3 swapness

内存回收包括文件页和匿名页：

* 对文件页的回收，是直接回收缓存，或者把脏页写回磁盘后再回收
* 对匿名页的回收，是通过 **Swap 机制**，把它们写入磁盘后再释放内存

Linux 提供了一个  /proc/sys/vm/swappiness 选项，用来调整使用 Swap 的积极程度：

swappiness 的范围是 0-100，数值越大，越积极使用 Swap，也就是更倾向于回收匿名页；数值越小，越消极使用 Swap，也就是更倾向于回收文件页

### 15 系统Swap升高的原因

#### 15.1 案例

Linux 本身支持两种类型的 Swap，即 Swap 分区和 Swap 文件，以Swap文件为例，运行如下命令开启Swap文件

```bash
# 创建swap文件
fallocate -l 500M /data/swapfile
# 修改权限，仅root用户可读写
chmod 600 /data/swapfile
# 配置swap文件
mkswap /data/swapfile
# 开启swap
swapon /data/swapfile
```

执行free看到swap添加成功

```bash
[root@VM_194_74_centos /data]# free
              total        used        free      shared  buff/cache   available
Mem:       16092196      562160      613616      295992    14916420    15135272
Swap:        511996           0      511996
```

执行dd命令，模拟大文件的读取

```bash
dd if=/dev/vdb1 of=/dev/null bs=1G count=400
```

执行sar查看内存和swap指标

```bash
[root@VM_194_74_centos ~]# sar -rS 3
Linux 3.10.107-1-tlinux2_kvm_guest-0051 (VM_194_74_centos)      07/05/20        _x86_64_        (8 CPU)

20:16:14    kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
20:16:17     12016228   4075968     25.33   1944876    394804   3089884     18.61   2364636   1364468        88

20:16:14    kbswpfree kbswpused  %swpused  kbswpcad   %swpcad
20:16:17       511996         0      0.00         0      0.00

20:16:17    kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
20:16:20     11542068   4550128     28.28   2405684    394868   3089856     18.61   2364984   1825212       120

20:16:17    kbswpfree kbswpused  %swpused  kbswpcad   %swpcad
20:16:20       511996         0      0.00         0      0.00
...

20:16:50    kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
20:16:53      6331744   9760452     60.65   7474548    395052   3089736     18.61   2364948   6894124        84

20:16:50    kbswpfree kbswpused  %swpused  kbswpcad   %swpcad
20:16:53       511996         0      0.00         0      0.00
...

20:17:44    kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
20:17:47        90140  16002056     99.44  13573540    392440   3089728     18.61   2180308  13149900       164

20:17:44    kbswpfree kbswpused  %swpused  kbswpcad   %swpcad
20:17:47       486836     25160      4.91       120      0.48
...

20:18:44    kbmemfree kbmemused  %memused kbbuffers  kbcached  kbcommit   %commit  kbactive   kbinact   kbdirty
20:18:47        87988  16004208     99.45  13658536    354504   3089760     18.61   2112144  13218932       140

20:18:44    kbswpfree kbswpused  %swpused  kbswpcad   %swpcad
20:18:47       403652    108344     21.16       140      0.13
```

可以看到，总的内存使用率（%memused）在不断增长，从开始的 25% 一直长到了 99%，并且主要内存都被缓冲区（kbbuffers）占用，大致的变化过程为：

* 刚开始，剩余内存（kbmemfree）不断减少，而缓冲区（kbbuffers）则不断增大，由此可知，剩余内存不断分配给了缓冲区；
* 一段时间后，剩余内存已经很小，而缓冲区占用了大部分内存。此时，Swap 的使用开始逐渐增大，缓冲区和剩余内存则只在小范围内波动

为什么Swap会升高呢？（按理来说应该先回收缓冲区中的内存，这属于可回收内存），观察/proc/zoneinfo指标如下

```bash
$ watch -d grep -A 15 'Normal' /proc/zoneinfo

Every 2.0s: grep -A 15 Normal /proc/zoneinfo                                                             Sun Jul  5 20:19:39 2020

Node 0, zone   Normal
  pages free     5200
        min      3268
        low      4085
        high     4902
        scanned  24
        spanned  3407872
        present  3407872
        managed  3276302
    nr_free_pages 5200
    nr_inactive_anon 134532
    nr_active_anon 246943
    nr_inactive_file 2466171
    nr_active_file 280987
    nr_unevictable 0
    nr_mlock     0
```

可以发现，剩余内存（pages_free）在一个小范围内不停地波动。当它小于页低阈值（pages_low) 时，又会突然增大到一个大于页高阈值（pages_high）的值

* 当剩余内存小于页低阈值时，系统会回收一些缓存和匿名内存，使剩余内存增大。其中，缓存的回收导致 sar 中的缓冲区减小，而匿名内存的回收导致了 Swap 的使用增大。
* 同时由于 dd 还在继续，剩余内存又会重新分配给缓存，导致剩余内存减少，缓冲区增大

利用proc 文件系统，可以查看进程 Swap 换出的虚拟内存大小，它保存在 /proc/pid/status 中的 VmSwap

```bash
[root@VM_194_74_centos /]# for file in /proc/*/status ; do awk '/VmSwap|Name|^Pid/{printf $2 " " $3}END{ print ""}' $file; done | sort -k 3 -n -r | head
systemd-journal 3048 86160 kB
writeback 50 
watchdog/7 41 
watchdog/6 36 
watchdog/5 31 
watchdog/4 26 
watchdog/3 21 
watchdog/2 16 
watchdog/1 11 
watchdog/0 10 
```

可以看到，使用swap较多的是systemd-journal进程

结束之后，需要关闭swap

```bash
swapoff -a
```

一般关闭swap并重新打开，可以这么执行(是一种常见的swap清理方法)

```bash
swapoff -a && swapon /data/swapfile
```

#### 15.2 小结

在内存资源紧张时，Linux 会通过 Swap ，把不常访问的匿名页换出到磁盘中，下次访问的时候再从磁盘换入到内存中来。你可以设置 /proc/sys/vm/min_free_kbytes，来调整系统定期回收内存的阈值；也可以设置 /proc/sys/vm/swappiness，来调整文件页和匿名页的回收倾向

当 Swap 变高时，你可以用 sar、/proc/zoneinfo、/proc/pid/status 等方法，查看系统和进程的内存使用情况，进而找出 Swap 升高的根源和受影响的进程

通常，降低 Swap 的使用，可以提高系统的整体性能。有几种常见的降低方法：

* 禁止 Swap，现在服务器的内存足够大，所以除非有必要，一般会**禁用 Swap**，大部分云平台中的虚拟机都默认禁止 Swap
* 如果实在需要用到 Swap，可以尝试**降低 swappiness** 的值，减少内存回收时 Swap 的使用倾向
* 响应延迟敏感的应用，如果它们可能在开启 Swap 的服务器中运行，你还可以用库函数 mlock() 或者 mlockall() **锁定内存**，阻止它们的内存换出

常见的三种清理缓存的方法：

* 清理pagecache

  ```bash
  echo 1 > /proc/sys/vm/drop_caches  # 或者 sysctl -w vm.drop_caches = 1
  ```

* 清理dentries和inodes

  ```bash
  echo 2 > /proc/sys/vm/drop_caches  # 或者 sysctl -w vm.drop_caches = 2
  ```

* 清理pagecache，dentries和inodes

  ```bash
  echo 3 > /proc/sys/vm/drop_caches  # 或者 sysctl -w vm.drop_caches = 3
  ```

* 使用sync命令来清理文件系统缓存，还会清理僵尸(zombie)对象和它们占用的内存

  ```bash
  sync
  ```

### 16 内存泄漏如何定位和解决



### 17 利用系统缓存优化程序运行效率



### 18 如何“快准狠”找到系统内存的问题

#### 18.1 内存性能指标

系统调用内存分配请求后，并不会立刻为其分配物理内存，而是在请求首次访问时，通过缺页异常来分配

缺页异常又分为下面两种场景：

* 可以直接从物理内存中分配时，被称为**次缺页异常**
* 需要磁盘 I/O 介入（比如 Swap）时，被称为**主缺页异常**

![img](https://static001.geekbang.org/resource/image/e2/36/e28cf90f0b137574bca170984d1e6736.png)

#### 18.2 分析内存性能瓶颈

分析过程如下图

* 先用 free 和 top，查看系统整体的内存使用情况
* 再用 vmstat 和 pidstat，查看一段时间的趋势，从而判断出内存问题的类型
* 最后进行详细分析，比如内存分配分析、缓存 / 缓冲区分析、具体进程的内存使用分析等

![img](https://static001.geekbang.org/resource/image/d7/fe/d79cd017f0c90b84a36e70a3c5dccffe.png)

#### 18.3 总结

内存常见的优化思路有这么几种

* 最好禁止 Swap。如果必须开启 Swap，降低 swappiness 的值，减少内存回收时 Swap 的使用倾向
* 减少内存的动态分配。比如，可以使用内存池、大页（HugePage）等
* 尽量使用缓存和缓冲区来访问数据。比如，可以使用堆栈明确声明内存空间，来存储需要缓存的数据；或者用 Redis 这类的外部缓存组件，优化数据的访问
* 使用 cgroups 等方式限制进程的内存使用情况。这样，可以确保系统内存不会被异常进程耗尽
* 通过 /proc/pid/oom_adj ，调整核心应用的 oom_score。这样，可以保证即使内存紧张，核心应用也不会被 OOM 杀死

### 19 文件系统和磁盘的区别

磁盘是一个存储设备（确切地说是块设备），可以被划分为不同的磁盘分区。而在磁盘或者磁盘分区上，还可以再创建文件系统，并挂载到系统的某个目录中。这样，系统就可以通过这个挂载目录，来读写文件

换句话说，磁盘是存储数据的块设备，也是文件系统的载体。所以，文件系统确实还是要通过磁盘，来保证数据的持久化存储

**Linux 中一切皆文件**。可以通过相同的文件接口，来访问磁盘和文件（比如 open、read、write、close 等）

* 通常说的“文件”，是指普通文件
* 磁盘和分区，是指块设备文件

在读写普通文件时，I/O 请求会首先经过文件系统，然后由文件系统负责，来与磁盘进行交互。而在读写块设备文件时，会跳过文件系统，直接与磁盘交互，也就是所谓的“裸 I/O”。文件系统管理的缓存，是 Cache 的一部分；而裸磁盘的缓存，用的正是Buffer

## IO性能篇

### 20 Linux文件系统如何工作

#### 20.1 索引节点和目录项

* 索引节点，简称inode，和文件一一对应，存储在磁盘中，记录文件的元数据
* 目录项，dentry，记录文件的名字、索引节点以及其他目录项的关联关系

举例说明，为文件创建的硬链接，会对应不同的目录项，他们都连接到同一个文件，索引节点相同

磁盘的最小单位是**扇区**，文件系统将连续的扇区组成逻辑块，以逻辑块为最小单位，来读写磁盘数据。常见的逻辑块4KB，由连续的8个扇区组成。

**示意图**

![img](https://static001.geekbang.org/resource/image/32/47/328d942a38230a973f11bae67307be47.png)



磁盘在执行文件系统格式化时，分为三个区域：超级块、索引节点和数据块区

* 超级块：整个文件系统的状态
* 索引节点区：存储索引节点
* 数据块区：存储文件数据



#### 20.2 虚拟文件系统

**示意图**

![img](https://static001.geekbang.org/resource/image/72/12/728b7b39252a1e23a7a223cdf4aa1612.png)

文件系统分类：

* 基于磁盘的文件系统：常见的 Ext4、XFS、OverlayFS 等，都是这类文件系统
* 基于内存的文件系统：常说的虚拟文件系统，不需要磁盘空间，但是占用内存。比如，/proc和/sys
* 网络文件系统：用来访问其他计算机的文件系统，比如NFS、SMB、iSCSI 等

**注意**：这些文件系统，要先挂载到 VFS 目录树中的某个子目录（称为**挂载点**），然后才能访问其中的文件。



#### 20.3 文件系统IO

根据是否利用标准库缓存，分为**缓冲IO和非缓冲IO**

* 缓存IO：利用标准库缓存，加速文件访问，标准库内部利用系统调用访问文件
* 非缓存IO：直接通过系统调用访问文件，不再经过标准库缓存

**注意**：这里的“缓冲”，是指**标准库内部实现的缓存**，最终还是需要通过系统调用，而系统调用还会通过**页缓存**，来减少磁盘的IO操作

根据是否利用操作系统的**页缓存**，分为**直接IO和非直接IO**

* 直接IO：跳过操作系统的页缓存，直接和**文件系统**交互来访问文件
* 非直接IO：先通过页缓存，再通过内核或者额外的系统调用，真正和磁盘交互（`O_DIRECT`标志）

根据应用程序是否阻塞自身，分为**阻塞IO和非阻塞IO**

* 阻塞 I/O：是指应用程序执行 I/O 操作后，如果没有获得响应，就会阻塞当前线程
* 非阻塞 I/O：是指应用程序执行 I/O 操作后，不会阻塞当前的线程，可以继续执行其他的任务，随后再通过**轮询或者事件通知**的形式，获取调用的结果

根据是否等待相应结果，分为**同步IO和异步IO**

* 同步IO：应用程序执行IO操作之后，要等到整个IO完成后，才能获得IO响应
* 异步IO：应用程序不用等待IO完成，会继续执行，等到IO执行完成，会以事件的方式通知应用程序

设置`O_SYNC`或者`O_DSYNC`，代表同步IO。如果是`O_DSYNC`，要等到文件数据写入磁盘之后，才能返回，如果是`O_SYNC`，是在`O_DSYNC`的基础上，要求文件**元数据**写入磁盘，才返回

设置`O_ASYNC`，代表异步IO，系统会再通过`SIGIO`或者`SIGPOLL`通知进程

#### 20.4 性能观测

##### 20.4.1 容量

`df`命令查看磁盘空间

```bash
$ df -h /dev/sda1 
Filesystem      Size  Used Avail Use% Mounted on 
/dev/sda1        29G  3.1G   26G  11% / 

# 查看索引节点所占的空间
$ df -i /dev/sda1 
Filesystem      Inodes  IUsed   IFree IUse% Mounted on 
/dev/sda1      3870720 157460 3713260    5% / 
```

当索引节点空间不足，但是磁盘空间充足时，很可能是过多小文件导致的。**解决方法**一般是删除这些小文件，或者移动到索引节点充足的其他磁盘区

##### 20.4.2 缓存

可以使用free或者vmstat，观察页缓存的大小

也可以查看/proc/meminfo

```bash
$ cat /proc/meminfo | grep -E "SReclaimable|Cached" 
Cached:           748316 kB 
SwapCached:            0 kB 
SReclaimable:     179508 kB 
```

内核使用slab机制，管理目录项和索引节点的缓存，/proc/meminfo给出了整体的slab大小，/proc/slabinfo可以查看每一种slab的缓存

```bash

$ cat /proc/slabinfo | grep -E '^#|dentry|inode' 
# name            <active_objs> <num_objs> <objsize> <objperslab> <pagesperslab> : tunables <limit> <batchcount> <sharedfactor> : slabdata <active_slabs> <num_slabs> <sharedavail> 
xfs_inode              0      0    960   17    4 : tunables    0    0    0 : slabdata      0      0      0 
... 
ext4_inode_cache   32104  34590   1088   15    4 : tunables    0    0    0 : slabdata   2306   2306      0hugetlbfs_inode_cache     13     13    624   13    2 : tunables    0    0    0 : slabdata      1      1      0 
sock_inode_cache    1190   1242    704   23    4 : tunables    0    0    0 : slabdata     54     54      0 
shmem_inode_cache   1622   2139    712   23    4 : tunables    0    0    0 : slabdata     93     93      0 
proc_inode_cache    3560   4080    680   12    2 : tunables    0    0    0 : slabdata    340    340      0 
inode_cache        25172  25818    608   13    2 : tunables    0    0    0 : slabdata   1986   1986      0 
dentry             76050 121296    192   21    1 : tunables    0    0    0 : slabdata   5776   5776      0 
```

其中，dentry代表目录项缓存，inode_cache代表VFS索引节点缓存，其他的就是各种文件系统的索引节点缓存



实际性能分析中，更常使用slabtop命令，来找出占用内存最多的缓存类型

示例如下：可以看到，目录项和索引节点占用了最多的 Slab 缓存，总共大约23M

```bash

# 按下c按照缓存大小排序，按下a按照活跃对象数排序 
$ slabtop 
Active / Total Objects (% used)    : 277970 / 358914 (77.4%) 
Active / Total Slabs (% used)      : 12414 / 12414 (100.0%) 
Active / Total Caches (% used)     : 83 / 135 (61.5%) 
Active / Total Size (% used)       : 57816.88K / 73307.70K (78.9%) 
Minimum / Average / Maximum Object : 0.01K / 0.20K / 22.88K 

  OBJS ACTIVE  USE OBJ SIZE  SLABS OBJ/SLAB CACHE SIZE NAME 
69804  23094   0%    0.19K   3324       21     13296K dentry 
16380  15854   0%    0.59K   1260       13     10080K inode_cache 
58260  55397   0%    0.13K   1942       30      7768K kernfs_node_cache 
   485    413   0%    5.69K     97        5      3104K task_struct 
  1472   1397   0%    2.00K     92       16      2944K kmalloc-2048 
```



### 21 Linux磁盘I/O工作原理

#### 21.1 磁盘

按照存储介质，磁盘分为：

* 机械磁盘，也称为硬盘驱动器（Hard Disk Driver），通常缩写为 HDD。机械磁盘主要由盘片和读写磁头组成，数据就存储在盘片的环状磁道中。在读写数据前，需要移动读写磁头，定位到数据所在的磁道，才能访问数据。如果 I/O 请求刚好连续，就不需要磁道寻址，可以获得最佳性能。这就是连续 I/O 的工作原理。与之相对应的是随机 I/O，它需要不停地移动磁头，来定位数据位置，读写速度就会比较慢
* 固态磁盘（Solid State Disk），通常缩写为 SSD，由固态电子元器件组成。固态磁盘不需要磁道寻址，不管是连续 I/O，还是随机 I/O 的性能，都比机械磁盘要好得多。

无论机械磁盘，还是固态磁盘，相同磁盘的随机 I/O 都要比连续 I/O 慢很多，原因是：

* 随机 I/O 需要更多的磁头寻道和盘片旋转，它的性能自然要比连续 I/O 慢
* 对固态磁盘来说，虽然它的随机性能比机械硬盘好很多，但同样存在“先擦除再写入”的限制。随机读写会导致大量的垃圾回收，所以相对应的，随机 I/O 的性能比起连续 I/O 来，也还是差了很多
* 连续 I/O 还可以通过预读的方式，来减少 I/O 请求的次数，这也是其性能优异的一个原因

最小读写单位：

* 机械硬盘的最小读写单位是扇区，一般512字节
* 固态硬盘的最小读写单位是页，一般是4KB或者8KB

按照接口，磁盘可分为 IDE（Integrated Drive Electronics）、SCSI（Small Computer System Interface） 、SAS（Serial Attached SCSI） 、SATA（Serial ATA） 、FC（Fibre Channel） 等

磁盘介入服务器时，按照不同的使用方式，会划分为不同的架构：

* 最简单的直接作为独立磁盘设备来使用
* 将多块磁盘组合成一个逻辑磁盘，构成冗余独立磁盘阵列（RAID），提高数据访问的性能，并增强数据存储的可靠性
* 最后一种，是将磁盘组合成网络存储集群，再通过NFS、SMB、iSCSI等网络存储协议，暴露给服务器使用

在Linux中，磁盘是作为一个块设备来管理，以块为单位来读写，支持随机读写。每个块设备赋予两个设备号，分别是主、次设备号，主设备号用在驱动程序中，用来区分设备类型；次设备号用来在多个同类设备编号

#### 21.2 通用块层

和VFS类似，为了减少不同块设备的差异带来的影响，Linux通过统一的通用块（块I/O层），管理不同的块设备

块设备层是处在文件系统和磁盘驱动中间的一个块设备抽象层，主要功能是：

* 向上为文件系统和应用程序提供访问块设备的标准接口；向下，把各种异构的磁盘块设备抽象为统一的块设备，提供统一框架管理这些设备的驱动程序
* 通用块层还会给文件系统和应用程序发来的 I/O 请求排队，并通过重新排序、请求合并等方式，提高磁盘读写的效率

对 I/O 请求排序的过程就是I/O调度，Linux支持四种I/O调度算法，分别是NONE、NOOP、CFQ以及DeadLine

* NONE，不使用任何调度，对I/O不作任何处理（常用在虚拟机，此时磁盘I/O完全由物理机负责）
* NOOP，先入先出调度算法（常用在SSD）
* CFQ（Completely Fair Schedule）完全公平调度器，很多Linux发行版的默认调度器，它为每个进程维护了一个I/O调度队列，按照时间片来均匀分配每个进程的I/O请求；还支持优先级调度，适用于大量进程的系统（如桌面、多媒体应用等）
* DeadLine调度算法，分别为读、写请求创建了不同的 I/O 队列，可以提高机械磁盘的吞吐量，并确保达到最终期限（deadline）的请求被优先处理，多用在 I/O 压力比较重的场景，比如数据库等

#### 21.3 I/O栈

![img](https://static001.geekbang.org/resource/image/14/b1/14bc3d26efe093d3eada173f869146b1.png)

根据这张 I/O 栈的全景图，可以看到存储系统 I/O 的工作原理

* 文件系统层，包括虚拟文件系统和其他各种文件系统的具体实现。它为上层的应用程序，提供标准的文件访问接口；对下会通过通用块层，来存储和管理磁盘数据
* 通用块层，包括块设备 I/O 队列和 I/O 调度器。它会对文件系统的 I/O 请求进行排队，再通过重新排序和请求合并，然后才要发送给下一级的设备层
* 设备层，包括存储设备和相应的驱动程序，负责最终物理设备的 I/O 操作

存储系统的 I/O ，通常是整个系统中最慢的一环。

 Linux 通过多种缓存机制来优化 I/O 效率。为了优化文件访问的性能，会使用页缓存、索引节点缓存、目录项缓存等多种缓存机制，以减少对下层块设备的直接调用。同样，为了优化块设备的访问效率，会使用缓冲区，来缓存块设备的数据

#### 21.4 磁盘性能指标

使用率、饱和度、IOPS、吞吐量以及响应时间五个指标，是磁盘性能的基本指标

* 使用率，是指磁盘处理 I/O 的时间百分比。过高的使用率（比如超过 80%），通常意味着磁盘 I/O 存在性能瓶颈
* 饱和度，是指磁盘处理 I/O 的繁忙程度。过高的饱和度，意味着磁盘存在严重的性能瓶颈。当饱和度为 100% 时，磁盘无法接受新的 I/O 请求
* IOPS（Input/Output Per Second），是指每秒的 I/O 请求数
* 吞吐量，是指每秒的 I/O 请求大小
* 响应时间，是指 I/O 请求从发出到收到响应的间隔时间

**注意**：

1. 使用率只考虑有没有 I/O，而不考虑 I/O 的大小。换句话说，当使用率是 100% 的时候，磁盘依然有可能接受新的 I/O 请求
2. 随机读写多（如数据库、大量小文件）的情况下主要关注IOPS，而顺序读写多（如流媒体）的情况下，主要关注吞吐量

在为应用程序的服务器选型时，要先对磁盘的 I/O 性能进行基准测试，以便可以准确评估，磁盘性能是否可以满足应用程序的需求

#### 21.5 磁盘I/O观测

使用iostat观测每块磁盘的使用情况，提供了每个磁盘的使用率、IOPS、吞吐量等各种常见的性能指标，这些指标实际上来自  /proc/diskstats

```bash
[root@VM_194_74_centos ~]# iostat -dx 1
Linux 3.10.107-1-tlinux2_kvm_guest-0051 (VM_194_74_centos)      07/10/20        _x86_64_        (8 CPU)

Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
vda               0.00     8.69    0.20    8.62     1.98   114.42    26.38     0.01    1.14    2.58    1.11   0.68   0.60
vdb              31.81     0.23    1.16    0.12   132.40     1.68   210.15     0.00    1.48    1.46    1.62   0.71   0.09
scd0              0.00     0.00    0.00    0.00     0.00     0.00    14.20     0.00    0.29    0.29    0.00   0.29   0.00

Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util
vda               0.00     9.00    0.00    3.00     0.00    48.00    32.00     0.01    2.67    0.00    2.67   1.33   0.40
vdb               0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00
scd0              0.00     0.00    0.00    0.00     0.00     0.00     0.00     0.00    0.00    0.00    0.00   0.00   0.00
```

各个指标解读如下

![img](https://static001.geekbang.org/resource/image/cf/8d/cff31e715af51c9cb8085ce1bb48318d.png)

**注意**：

* %util  ，就是我们前面提到的磁盘 I/O 使用率；
* r/s+  w/s  ，就是 IOPS；
* rkB/s+wkB/s ，就是吞吐量；
* r_await+w_await ，就是响应时间

在观测指标时，可以结合请求的大小（ rareq-sz 和 wareq-sz）一起分析

#### 21.6 进程I/O观测

pidstat可以实时查看每个进程的I/O情况

```bash
[root@VM_194_74_centos ~]# pidstat -d 1
Linux 3.10.107-1-tlinux2_kvm_guest-0051 (VM_194_74_centos)      07/10/20        _x86_64_        (8 CPU)

17:53:51      UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s  Command
17:53:52        0     17517      0.00      3.96      0.00  sap1004

17:53:52      UID       PID   kB_rd/s   kB_wr/s kB_ccwr/s  Command
17:53:53        0     17508      0.00      4.00      0.00  sap1002
17:53:53        0     17517      0.00      4.00      0.00  sap1004
...
```

指标如下：

* 用户 ID（UID）和进程 ID（PID） 
* 每秒读取的数据大小（kB_rd/s），单位是 KB
* 每秒发出的写请求数据大小（kB_wr/s），单位是 KB
* 每秒取消的写请求数据大小（kB_ccwr/s） ，单位是 KB

 ### 22 狂打日志问题定位



### 23 为什么磁盘I/O延迟很高？

### 24 SQL查询慢的问题定位？

### 25 Redis响应严重延迟的原因

### 26 套路篇：如何迅速分析系统I/O的瓶颈？

### 27 套路篇：磁盘I/O性能优化的几个思路



## 网络性能篇

### 28 Linux网络原理

#### 28.1 Linux网络栈

Linux网络栈示意图如下:

* 最上层的应用程序，需要通过系统调用，来跟套接字接口进行交互；
* 套接字的下面，就是传输层、网络层和网络接口层；
* 最底层，则是网卡驱动程序以及物理网卡设备。

<img src="https://static001.geekbang.org/resource/image/c7/ac/c7b5b16539f90caabb537362ee7c27ac.png" width="600">

> **网卡**是发送和接收网络包的基本设备。
>
> 在系统启动过程中，网卡通过内核中的**网卡驱动程序注册**到系统中。
>
> 在网络收发过程中，内核通过中断跟网卡进行交互。由于网络包的处理非常复杂，网卡硬中断只处理最核心的网卡数据读取或发送，而协议栈中的大部分逻辑，都会放到**软中断**中处理。

#### 28.2 Linux网络收发流程

##### 28.2.1 网络报的接收流程

* 当一个网络帧到达网卡后，网卡会通过 **DMA 方式**，把这个网络包放到**收包队列**中；然后通过**硬中断**，告诉中断处理程序已经收到了网络包，网卡中断处理程序会为网络帧分配**内核数据结构（sk_buff）**，并将其拷贝到 sk_buff 缓冲区中
* 再通过软中断，通知内核收到了新的网络帧
* 内核协议栈从缓冲区中取出网络帧，并通过网络协议栈，从下到上逐层处理这个网络帧，如下图左半部分

<img src="https://static001.geekbang.org/resource/image/3a/65/3af644b6d463869ece19786a4634f765.png" width="600">

##### 28.2.2 网络包的发送流程

网络报发送流程如上图右半部分

* 应用程序调用 Socket API（比如 sendmsg）发送网络包。由于这是一个系统调用，会陷入到**内核态的套接字层**中。套接字层会把数据包放到 Socket 发送缓冲区中
* 网络协议栈从 Socket 发送缓冲区中，取出数据包；再按照 TCP/IP 栈，从上到下逐层处理
* 网络包再送到网络接口层，进行物理地址寻址，以找到下一跳的 MAC 地址。然后添加帧头和帧尾，放到发包队列中
* 接下来会有**软中断通知驱动程序**：发包队列中有新的网络帧需要发送
* 驱动程序通过 DMA ，从发包队列中读出网络帧，并通过物理网卡把它发送出去

### 29 Linux网络性能指标

#### 29.1 性能指标

* **带宽**，表示链路的**最大传输速率**，单位通常为 b/s （比特 / 秒）。
* **吞吐量**，表示单位时间内成功传输的数据量，单位通常为 b/s（比特 / 秒）或者 B/s（字节 / 秒）。**吞吐量受带宽限制**，而吞吐量 / 带宽，也就是该网络的使用率。
* **延时**，表示从网络请求发出后，一直到收到远端响应，所需要的时间延迟。在不同场景中，这一指标可能会有不同含义。比如，它可以表示，建立连接需要的时间（比如 TCP 握手延时），或一个数据包往返所需的时间（比如 RTT）。
* **PPS**，是 Packet Per Second（包 / 秒）的缩写，表示以**网络包为单位的传输速率**。PPS 通常用来评估**网络的转发能力**，比如硬件交换机，通常可以达到线性转发（即 PPS 可以达到或者接近理论最大值）。而基于 Linux 服务器的转发，则容易受网络包大小的影响。

另外，**网络的可用性**（网络能否正常通信）、**并发连接数**（TCP 连接数量）、**丢包率**（丢包百分比）、**重传率**（重新传输的网络包比例）等也是常用的性能指标。

#### 29.2 网络配置

使用命令`ifconfig`或者`ip`查看

```bash
[root@VM_194_74_centos ~]# ifconfig eth1
eth1: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
        inet 9.134.194.74  netmask 255.255.248.0  broadcast 9.134.199.255
        ether 52:54:00:82:12:e8  txqueuelen 1000  (Ethernet)
        RX packets 70297502  bytes 34143392231 (31.7 GiB)
        RX errors 0  dropped 0  overruns 0  frame 0
        TX packets 78816203  bytes 45528648722 (42.4 GiB)
        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0

[root@VM_194_74_centos ~]# ip -s  addr show dev eth1
2: eth1: <BROADCAST,MULTICAST,UP,LOWER_UP> mtu 1500 qdisc mq state UP qlen 1000
    link/ether 52:54:00:82:12:e8 brd ff:ff:ff:ff:ff:ff
    inet 9.134.194.74/21 brd 9.134.199.255 scope global eth1
       valid_lft forever preferred_lft forever
    RX: bytes  packets  errors  dropped overrun mcast   
    34143407013 70297654 0       0       0       0       
    TX: bytes  packets  errors  dropped carrier collsns 
    45528723929 78816328 0       0       0       0  
```

第一，网络接口的状态标志。ifconfig 输出中的 RUNNING ，或 ip 输出中的 LOWER_UP ，都表示物理网络是连通的，即网卡已经连接到了交换机或者路由器中。如果你看不到它们，通常表示网线被拔掉了。

第二，MTU 的大小。MTU 默认大小是 1500，根据网络架构的不同（比如是否使用了 VXLAN 等叠加网络），你可能需要调大或者调小 MTU 的数值。

第三，网络接口的 IP 地址、子网以及 MAC 地址。这些都是保障网络功能正常工作所必需的，你需要确保配置正确。

第四，网络收发的字节数、包数、错误数以及丢包情况，特别是 TX 和 RX 部分的 errors、dropped、overruns、carrier 以及 collisions 等指标不为 0 时，通常表示出现了网络 I/O 问题。其中：

* errors 表示发生错误的数据包数，比如校验错误、帧同步错误等；
* dropped 表示丢弃的数据包数，即数据包已经收到了 Ring Buffer，但因为内存不足等原因丢包；
* overruns 表示超限数据包数，即网络 I/O 速度过快，导致 Ring Buffer 中的数据包来不及处理（队列满）而导致的丢包；
* carrier 表示发生 carrirer 错误的数据包数，比如双工模式不匹配、物理电缆出现问题等；
* collisions 表示碰撞数据包数。

#### 29.3 套接字信息

使用`netstat`或`ss`来查看**套接字、网络栈、网络接口以及路由表的信息**

```bash
# head -n 3 表示只显示前面3行
# -l 表示只显示监听套接字
# -n 表示显示数字地址和端口(而不是名字)
# -p 表示显示进程信息
[root@VM_194_74_centos ~]# netstat -nlp | head -n 3
Active Internet connections (only servers)
Proto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name    
tcp        0      0 0.0.0.0:36000           0.0.0.0:*               LISTEN      7788/sshd  

# -l 表示只显示监听套接字
# -t 表示只显示 TCP 套接字
# -n 表示显示数字地址和端口(而不是名字)
# -p 表示显示进程信息
[root@VM_194_74_centos ~]# ss -ltnp | head -n 3
State      Recv-Q Send-Q Local Address:Port               Peer Address:Port              
LISTEN     0      128          *:36000                    *:*                   users:(("sshd",pid=7788,fd=3))
LISTEN     0      128    127.0.0.1:5432                     *:*                   users:(("postgres",pid=2534,fd=3))
```

其中，**接收队列（Recv-Q）和发送队列（Send-Q）**需要关注，它们通常应该是 0。当你发现它们不是 0 时，说明有网络包的堆积发生

当套接字处于连接状态（Established）时，

* Recv-Q 表示套接字缓冲还没有被应用程序取走的字节数（即接收队列长度）。而

* Send-Q 表示还没有被远端主机确认的字节数（即发送队列长度）。

当套接字处于监听状态（Listening）时，

* Recv-Q 表示当前全连接队列（accept 队列）的长度（backlog含义参考链接 [详解socket中的backlog 参数](https://zhuanlan.zhihu.com/p/104874605)）

* Send-Q 表示全连接队列的最大长度

<img src="D:\CS相关\学习笔记\Linux学习笔记\image-20200615090347978.png" width="800">

#### 29.4 协议栈统计信息

使用`netstat`或`ss`命令

```bash
$ netstat -s
...
Tcp:
    3244906 active connection openings
    23143 passive connection openings
    115732 failed connection attempts
    2964 connection resets received
    1 connections established
    13025010 segments received
    17606946 segments sent out
    44438 segments retransmitted
    42 bad segments received
    5315 resets sent
    InCsumErrors: 42
...

$ ss -s
Total: 186 (kernel 1446)
TCP:   4 (estab 1, closed 0, orphaned 0, synrecv 0, timewait 0/0), ports 0

Transport Total     IP        IPv6
*    1446      -         -
RAW    2         1         1
UDP    2         2         0
TCP    4         3         1
...
```

#### 29.5 网络吞吐和PPS

使用`sar`命令，加上`-n`参数，可以查看网络的统计信息，比如网络接口（DEV）、网络接口错误（EDEV）、TCP、UDP、ICMP 等

```bash
# 数字1表示每隔1秒输出一组数据
$ sar -n DEV 1
Linux 4.15.0-1035-azure (ubuntu)   01/06/19   _x86_64_  (2 CPU)

13:21:40        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
13:21:41         eth0     18.00     20.00      5.79      4.25      0.00      0.00      0.00      0.00
13:21:41      docker0      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
13:21:41           lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
```

* rxpck/s 和 txpck/s 分别是接收和发送的 PPS，单位为包 / 秒。
* rxkB/s 和 txkB/s 分别是接收和发送的吞吐量，单位是 KB/ 秒。
* rxcmp/s 和 txcmp/s 分别是接收和发送的压缩数据包数，单位是包 / 秒。
* %ifutil 是网络接口的使用率，即半双工模式下为 (rxkB/s+txkB/s)/Bandwidth，而全双工模式下为 max(rxkB/s, txkB/s)/Bandwidth。

Bandwidth 可以用 ethtool 来查询，它的单位通常是 Gb/s 或者 Mb/s(千兆网卡或者万兆网卡的单位都是bit)

```bash
$ ethtool eth0 | grep Speed
  Speed: 1000Mb/s
```

#### 29.6 连通性和延时

使用命令`ping`，来测试远程主机的连通性和延时（基于 **ICMP 协议**）

如下，测试本机到 114.114.114.114 这个 IP 地址的连通性和延时

```bash
# -c3表示发送三次ICMP包后停止
$ ping -c3 114.114.114.114
PING 114.114.114.114 (114.114.114.114) 56(84) bytes of data.
64 bytes from 114.114.114.114: icmp_seq=1 ttl=54 time=244 ms
64 bytes from 114.114.114.114: icmp_seq=2 ttl=47 time=244 ms
64 bytes from 114.114.114.114: icmp_seq=3 ttl=67 time=244 ms

--- 114.114.114.114 ping statistics ---
3 packets transmitted, 3 received, 0% packet loss, time 2001ms
rtt min/avg/max/mdev = 244.023/244.070/244.105/0.034 ms
```

ping 的输出，可以分为两部分：

* 每个 ICMP 请求的信息，包括 ICMP 序列号（icmp_seq）、TTL（生存时间，或者跳数）以及往返延时。
* 三次 ICMP 请求的汇总

### 30 C10K和C100K问题

#### 30.1 C10K

C10K代表同时处理10000个请求

从资源上来说，对 2GB 内存和千兆网卡的服务器来说，同时处理 10000 个请求，只要每个请求处理占用不到 200KB（2GB/10000）的内存和 100Kbit （1000Mbit/10000）的网络带宽就可以

从软件上来看，主要是网络I/O模型的问题，在C10K之前，Linux主要是**同步阻塞**的方式，每个请求都分配一个进程或者线程，而10000个进程或者线程的调度、上下文切换和内存，都可能成为瓶颈

需要解决的问题：

* 怎样在一个线程内处理多个请求，也就是要在一个线程内响应多个网络 I/O？

##### 30.1.1 I/O模型优化

异步、非阻塞I/O的思路：I/O多路复用

> 两种 I/O 事件通知的方式：**水平触发和边缘触发**
>
> 水平触发：只要文件描述符可以非阻塞地执行 I/O ，就会触发通知。也就是说，应用程序可以随时检查文件描述符的状态，然后再根据状态，进行 I/O 操作。
>
> 边缘触发：只有在文件描述符的状态发生改变（也就是 I/O 请求达到）时，才发送一次通知。这时候，应用程序需要尽可能多地执行 I/O，直到无法继续读写，才可以停止。如果 I/O 没执行完，或者因为某种原因没来得及处理，那么这次通知也就丢失了

* 第一种，使用非阻塞 I/O 和水平触发通知，比如使用 select 或者 poll
* 第二种，使用非阻塞 I/O 和边缘触发通知，比如 epoll（在select和poll基础上进行优化）
* 第三种，使用异步 I/O（Asynchronous I/O，简称为 AIO

##### 30.1.2 工作模型优化

I/O多路复用有两种主要的工作模式：

* **第一种**：主进程 + 多个 worker 子进程（比如nginx），主要流程是：
  * 主进程执行 bind() + listen() 后，创建多个子进程；
  * 在每个子进程中，都通过 accept() 或 epoll_wait() ，来处理相同的套接字

<img src="https://static001.geekbang.org/resource/image/45/7e/451a24fb8f096729ed6822b1615b097e.png" width="600">

**注意**：accept() 和 epoll_wait() 调用，还存在一个**惊群**的问题(当网络 I/O 事件发生时，多个进程被同时唤醒，但实际上只有一个进程来响应这个事件，其他被唤醒的进程都会重新休眠)

为了避免**惊群问题**， Nginx 在每个 worker 进程中，都增加一个了**全局锁**（accept_mutex）。这些 worker 进程需要首先竞争到锁，只有竞争到锁的进程，才会加入到 epoll 中，这样就确保只有一个 worker 子进程被唤醒

* **第二种**：监听到相同端口的多进程模型，所有的进程都监听相同的端口，有各自的套接字，开启 **SO_REUSEPORT** 选项(Linux 3.9+才支持)，由内核负责将请求负载均衡到这些监听进程中去

<img src="https://static001.geekbang.org/resource/image/90/bd/90df0945f6ce5c910ae361bf2b135bbd.png" width="600">

#### 30.2 C1000K

C1000K代表同时有100w个请求

* 从物理资源上来说，100 万个请求需要大量的系统资源
  * 内存：假设每个请求需要 16KB 内存的话，那么总共就需要大约 15 GB 内存
  * 带宽：假设只有 20% 活跃连接，即使每个连接只需要 1KB/s 的吞吐量，总共需要200000 * 8 / 1024 /1024 = 1.6 Gb/s 的吞吐量，千兆网卡已经不能满足，需要配置万兆网卡
* 从软件资源上来说，大量的连接也会占用大量的软件资源，比如**文件描述符的数量、连接状态的跟踪（CONNTRACK）、网络协议栈的缓存大小**（比如套接字读写缓存、TCP 读写缓存）等等，也会带来**大量的中断处理**。

**优化**：在I/O多路复用的基础上，需要多队列网卡、硬中断负载均衡、CPU 绑定、RPS/RFS（软中断负载均衡到多个 CPU 核上），以及将网络包的处理卸载（Offload）到网络设备（如 TSO/GSO、LRO/GRO、VXLAN OFFLOAD）等各种硬件和软件的优化

#### 30.3 C10M

同时有1000w个请求，解决方法是**跳过内核协议栈**，将网络包直接送到要处理的应用程序

* 第一种机制：DPDK，用户网络的标准，跳过内核协议栈，直接由用户态进程通过轮询的方式来处理网络请求

<img src="https://static001.geekbang.org/resource/image/99/3a/998fd2f52f0a48a910517ada9f2bb23a.png" width="600">

* 第二种机制：XDP（eXpress Data Path），Linux 内核提供的一种高性能网络数据路径，它允许网络包，在进入内核协议栈之前，就进行处理

<img src="https://static001.geekbang.org/resource/image/06/be/067ef9df4212cd4ede3cffcdac7001be.png" width="600">

### 31 怎么评估系统的网络性能

#### 31.1 各协议层的性能测试

##### 31.1.1 转发性能

`hping3`工具：测试网络包的处理能力

##### 31.1.2 TCP/UDP性能

`iperf`命令测试



## 问题记录

#### 19 swap使用升高

1. 文件页和匿名页的回收

#### 21 系统内存套路篇

1. cgroups等方式限制进程内存使用情况  ->   cgroup学习
2. 主缺页异常和次缺页异常

#### Linux文件系统怎么工作

1. 目录项、目录的区别（目录也是文件，可以用inode节点表示，而目录项在系统缓存中，如何构成目录结构？）

>  内存中的目录项指向目录对应的inode节点，目录inode中的数据指针指向磁盘中的数据块，数据块中包含着目录下的文件列表，从而映射到子目录下

